{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9722f0f6-deef-43b1-bb64-bb1a1f6597b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "GCBC with point maze (with multi-goal + color state space)\n",
    "'''\n",
    "from __future__ import print_function, division, unicode_literals\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import io\n",
    "import json\n",
    "from io import open\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import distributions as pyd\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.ion()   # interactive mode - o\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "lang_model = SentenceTransformer('all-MiniLM-L6-v2', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35dc18f8-9c07-4770-b61e-2126bbc49078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom weight init for Conv2D and Linear layers\n",
    "def weight_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.orthogonal_(m.weight.data)\n",
    "        if hasattr(m.bias, \"data\"):\n",
    "            m.bias.data.fill_(0.0)\n",
    "                \n",
    "# helper mlp init function\n",
    "def mlp(input_dim, output_dim, hidden_dim, hidden_depth, output_mod=None):\n",
    "    if hidden_depth == 0:\n",
    "        mods = [nn.Linear(input_dim, output_dim)]\n",
    "    else:\n",
    "        mods = [nn.Linear(input_dim, hidden_dim), nn.ReLU(inplace=True)]\n",
    "        for i in range(hidden_depth - 1):\n",
    "            mods += [nn.Linear(hidden_dim, hidden_dim), nn.ReLU(inplace=True)]\n",
    "        mods.append(nn.Linear(hidden_dim, output_dim))\n",
    "    if output_mod is not None:\n",
    "        mods.append(output_mod)\n",
    "    trunk = nn.Sequential(*mods)\n",
    "    return trunk\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "# MLP policy\n",
    "class MLPPolicy(nn.Module):\n",
    "    def __init__(\n",
    "        self, obs_dim, action_dim, hidden_dim, hidden_depth, output_mod=None\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.trunk = mlp(input_dim, output_dim, hidden_dim, hidden_depth, output_mod)\n",
    "        self.outputs = dict()\n",
    "        self.apply(weight_init)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.trunk(x)\n",
    "\n",
    "# MLP policy\n",
    "class CNNPolicy(nn.Module):\n",
    "    def __init__(\n",
    "        self, goal_dim, action_dim, hidden_size, mask=False, output_mod=None):\n",
    "        super().__init__()\n",
    "        self.mask = mask\n",
    "        self.goal = mlp(goal_dim, hidden_size, hidden_dim=0, hidden_depth=0, output_mod=None) # => hidden_size\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(3,32,kernel_size=8,stride=4), nn.ReLU(inplace=True), nn.BatchNorm2d(32), #(b_size,3,36,36)=>(b_size,32,8,8)\n",
    "            nn.Conv2d(32,64,kernel_size=4,stride=2), nn.ReLU(inplace=True), nn.BatchNorm2d(64), #(b_size,32,8,8)=>(b_size,64,3,3)\n",
    "            nn.Conv2d(64,32,kernel_size=3,stride=1), nn.LeakyReLU(inplace=True), Flatten(), nn.BatchNorm1d(32), #(b_size,64,3,3)=>(b_size,32,1,1)=>(b_size,32*1*1)\n",
    "            nn.Linear(32*1*1, hidden_size) #(b_size,32*1*1)=>(b_size,hidden_size)\n",
    "        )\n",
    "        self.process = mlp(hidden_size*2, 1*36*36, hidden_dim=1000, hidden_depth=1, output_mod=nn.Sigmoid()) #(b_size,hidden_size*2)=>(b_size,32*1*1)\n",
    "        # UNet deconv mask --------------------------------------------------------------------------------------------------\n",
    "        #self.deconv = nn.Sequential(\n",
    "        #    nn.ConvTranspose2d(32, 64, kernel_size=3, stride=1), nn.LeakyReLU(inplace=True), nn.BatchNorm2d(64), #(b_size,32*1*1)=>(b_size,64,3,3)\n",
    "        #    nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2), nn.LeakyReLU(inplace=True), nn.BatchNorm2d(32), #(b_size,64,3,3)=>(b_size,32,8,8)\n",
    "        #    nn.ConvTranspose2d(32, 1, kernel_size=8, stride=4), nn.Sigmoid(), #(b_size,32,8,8)=>(b_size,3,36,36)\n",
    "        #)\n",
    "        self.cnntrunk = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=8, stride=4), nn.ReLU(inplace=True), nn.BatchNorm2d(32), #(b_size,3,36,36)=>(b_size,32,8,8)\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2), nn.ReLU(inplace=True), nn.BatchNorm2d(64), #(b_size,32,8,8)=>(b_size,64,3,3)\n",
    "            nn.Conv2d(64, 32, kernel_size=3, stride=1), nn.LeakyReLU(inplace=True), nn.BatchNorm2d(32), Flatten(), #(b_size,64,3,3)=>(b_size,32,1,1)=>(b_size,32*1*1)\n",
    "            nn.Linear(32*1*1, action_dim)#, nn.LeakyReLU(inplace=True), nn.BatchNorm1d(32), #(b_size,32*1*1)=>(b_size,hidden_size)\n",
    "            #nn.Linear(32, action_dim) #(b_size,hidden_size)=>(b_size,action_dim)\n",
    "        )\n",
    "        self.mlptrunk = mlp(hidden_size*2, action_dim, hidden_dim=100, hidden_depth=1) #(b_size,hidden_size*2)=>(b_size,action_dim)\n",
    "        self.apply(weight_init)\n",
    "\n",
    "    def forward(self, goal, state, gt_mask):\n",
    "        state = state/255.0 # process image + switch channels\n",
    "        state = state.permute(0,3,1,2)\n",
    "        state_embed = self.conv(state)\n",
    "        goal_embed = self.goal(goal) # process goal\n",
    "        goal_state = torch.cat((goal_embed,state_embed),dim=1) # process goal + state\n",
    "        \n",
    "        if self.mask:\n",
    "            img_mask = self.process(goal_state)\n",
    "            img_mask = img_mask.reshape(-1,1,36,36)\n",
    "            #img_mask = img_mask.reshape(-1,32,1,1)\n",
    "            #img_mask = self.deconv(img_mask) # deconv for mask\n",
    "            #--------------------- test with gt mask\n",
    "            #img_mask = gt_mask.reshape((-1, 36, 36, 1)) # reshape to 1 channel\n",
    "            #img_mask = np.repeat(img_mask, 3, axis=3) # duplicate across 3 channels\n",
    "            #img_mask = img_mask.permute(0,3,1,2) # process channel switch\n",
    "            #---------------------\n",
    "            masked_state = state * img_mask # apply mask to full state\n",
    "            pred = self.cnntrunk(masked_state)\n",
    "            return [pred, masked_state, img_mask]\n",
    "        else:\n",
    "            pred = self.mlptrunk(goal_state)\n",
    "            return [pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddefccc1-0cd0-4cc4-bf43-e15059ca919f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Goal-conditioned Point Maze (with multi state + color)\n",
    "import gym\n",
    "import gym.wrappers\n",
    "\n",
    "class PointEnvGrid(gym.Env):\n",
    "    def __init__(self):\n",
    "        self.pos = np.array([99., 99.])\n",
    "        self.obj1_pos = np.array([99., 99.])\n",
    "        self.obj1_color = np.array([99., 99., 99., 99.])\n",
    "        self.obj1_shape = np.array([99., 99., 99., 99.])\n",
    "        self.obj2_pos = np.array([99., 99.])\n",
    "        self.obj2_color = np.array([99., 99., 99., 99.])\n",
    "        self.obj2_shape = np.array([99., 99., 99., 99.])\n",
    "        self.goal = np.array(['go to the red X'])\n",
    "        self.goal_pos = np.array([99., 99.])\n",
    "        self.goal_color = np.array([99., 99., 99., 99.])\n",
    "        self.goal_shape = np.array([99., 99., 99., 99.])\n",
    "        self.max_vel = 1.\n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            -np.inf * np.ones(14), np.inf * np.ones(14)\n",
    "        )\n",
    "        self.action_space = gym.spaces.Box(-np.ones(2), np.ones(2))\n",
    "        self.action_space.seed(0)\n",
    "        self.observation_space.seed(0)\n",
    "\n",
    "    # creates test env with defined goal locations + colors\n",
    "    def reset(self, agent_pos=[0,1,2,3], obj_pos=[0,1,2,3], obj_colors=[0,1,2,3], obj_shapes=[0,1,2,3], scalar=5, obstacle=False):\n",
    "        # generates agent+objs without overlap\n",
    "        agent_loc = np.random.choice(agent_pos)\n",
    "        obj_pos = copy.deepcopy(obj_pos)\n",
    "        if agent_loc in obj_pos:\n",
    "            obj_pos.remove(agent_loc)\n",
    "        self.pos = self.gen_pos(agent_loc, scalar)\n",
    "        \n",
    "        if len(obj_pos) == 1:\n",
    "            self.obj1_pos = self.gen_pos(obj_pos[0], scalar)\n",
    "            self.obj1_color = self.gen_color(obj_colors)\n",
    "            self.obj1_shape = self.gen_shape(obj_shapes)\n",
    "            \n",
    "            self.goal_pos = self.obj1_pos\n",
    "            self.goal_color = self.obj1_color\n",
    "            self.goal_shape = self.obj1_shape\n",
    "            if obstacle:\n",
    "                self.obj2_pos = self.gen_pos(4, scalar)\n",
    "                self.obj2_color = self.gen_color([1])\n",
    "                self.obj2_shape = self.gen_shape([1])\n",
    "        else:\n",
    "            obj1_loc, obj2_loc = random.sample(obj_pos, 2)\n",
    "            self.obj1_pos = self.gen_pos(obj1_loc, scalar)\n",
    "            self.obj1_color = self.gen_color(obj_colors)\n",
    "            self.obj1_shape = self.gen_shape(obj_shapes)\n",
    "            self.obj2_pos = self.gen_pos(obj2_loc, scalar)\n",
    "            self.obj2_color = self.gen_color(obj_colors)\n",
    "            self.obj2_shape = self.gen_shape(obj_shapes)\n",
    "\n",
    "            # choose goal from random in objects\n",
    "            goal_obj = random.randint(1, 2)\n",
    "            if goal_obj == 1:\n",
    "                self.goal_pos = self.obj1_pos\n",
    "                self.goal_color = self.obj1_color\n",
    "                self.goal_shape = self.obj1_shape\n",
    "            elif goal_obj == 2:\n",
    "                self.goal_pos = self.obj2_pos\n",
    "                self.goal_color = self.obj2_color\n",
    "                self.goal_shape = self.obj2_shape\n",
    "        self.goal = np.array(['go to the ' + get_color(self.goal_color) + ' ' + get_shape(self.goal_shape)])\n",
    "        return self.get_full_obs()\n",
    "\n",
    "    def get_obs(self):\n",
    "        return copy.deepcopy(np.concatenate([self.pos, self.obj1_pos, self.obj1_color, self.obj1_shape, self.obj2_pos, self.obj2_color, self.obj2_shape, self.goal_color, self.goal_shape]))\n",
    "    \n",
    "    def get_full_obs(self):\n",
    "        return copy.deepcopy(np.concatenate([self.pos, self.obj1_pos, self.obj1_color, self.obj1_shape, self.obj2_pos, self.obj2_color, self.obj2_shape, self.goal_pos, self.goal_color, self.goal_shape]))\n",
    "    \n",
    "    def step(self, action: np.ndarray):\n",
    "        self.pos += self.max_vel*action\n",
    "        reward = -np.linalg.norm((self.pos - self.goal_pos))\n",
    "        return self.get_full_obs(), reward, False, {}\n",
    "\n",
    "    # given a range of areas, randomly selects and generates position\n",
    "    def gen_pos(self, location, scalar):\n",
    "        if location == 0:\n",
    "            pos = np.array([-1.*scalar, 1.*scalar])\n",
    "        elif location == 1:\n",
    "            pos = np.array([1.*scalar, 1.*scalar])\n",
    "        elif location == 2:\n",
    "            pos = np.array([1.*scalar, -1.*scalar])\n",
    "        elif location == 3:\n",
    "            pos = np.array([-1.*scalar, -1.*scalar])\n",
    "        elif location == 4:\n",
    "            pos = np.array([-0.1*scalar, 0.2*scalar])\n",
    "        return pos\n",
    "\n",
    "    def gen_color(self, colors):\n",
    "        one_hot_color = np.zeros(shape=4) # defines total number of colors to choose from\n",
    "        rand_color = random.choice(colors) # samples color from range\n",
    "        one_hot_color[rand_color] = 1.\n",
    "        return one_hot_color\n",
    "\n",
    "    def gen_shape(self, shapes):\n",
    "        one_hot_shape = np.zeros(shape=4)\n",
    "        rand_shape = random.choice(shapes)\n",
    "        one_hot_shape[rand_shape] = 1.\n",
    "        return one_hot_shape\n",
    "\n",
    "class PointEnvComplex(gym.Env):\n",
    "    def __init__(self):\n",
    "        self.pos = np.array([99., 99.])\n",
    "        self.obj1_pos = np.array([99., 99.])\n",
    "        self.obj1_color = np.array([99., 99., 99.])\n",
    "        self.obj2_pos = np.array([99., 99.])\n",
    "        self.obj2_color = np.array([99., 99., 99.])\n",
    "        self.goal = np.array(['go to the red star'])\n",
    "        self.goal_pos = np.array([99., 99.])\n",
    "        self.goal_color = np.array([99., 99., 99.])\n",
    "        self.max_vel = 1.\n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            -np.inf * np.ones(14), np.inf * np.ones(14)\n",
    "        )\n",
    "        self.action_space = gym.spaces.Box(-np.ones(2), np.ones(2))\n",
    "        self.action_space.seed(0)\n",
    "        self.observation_space.seed(0)\n",
    "\n",
    "    # creates test env with defined goal locations + colors\n",
    "    def reset(self, obj_angles=360, obj_colors=[0,1,2], discretize=10):\n",
    "        self.pos = np.array([0., 0.])\n",
    "        self.obj1_pos, self.obj1_color = self.gen_obj(obj_angles, obj_colors, discretize)\n",
    "        self.obj2_pos, self.obj2_color = self.gen_obj(obj_angles, obj_colors, discretize)\n",
    "\n",
    "        # choose goal from random in objects\n",
    "        goal_obj = random.randint(1, 2)\n",
    "        if goal_obj == 1:\n",
    "            self.goal_pos = self.obj1_pos\n",
    "            self.goal_color = self.obj1_color\n",
    "        elif goal_obj == 2:\n",
    "            self.goal_pos = self.obj2_pos\n",
    "            self.goal_color = self.obj2_color\n",
    "        self.goal = np.array(['go to the ' + get_color(self.goal_color) + ' square'])\n",
    "        return self.get_obs()\n",
    "\n",
    "    def get_obs(self):\n",
    "        return copy.deepcopy(np.concatenate([self.pos, self.obj1_pos, self.obj1_color, self.obj2_pos, self.obj2_color, self.goal_color]))\n",
    "    \n",
    "    def get_full_obs(self):\n",
    "        return copy.deepcopy(np.concatenate([self.pos, self.obj1_pos, self.obj1_color, self.obj2_pos, self.obj2_color, self.goal_pos, self.goal_color]))\n",
    "    \n",
    "    def step(self, action: np.ndarray):\n",
    "        self.pos += self.max_vel*action\n",
    "        reward = -np.linalg.norm((self.pos - self.goal_pos))\n",
    "        return self.get_full_obs(), reward, False, {}\n",
    "\n",
    "    # function to generate object based on angles, colors, and discretization ranges\n",
    "    def gen_obj(self, obj_angles, obj_colors, discretize):\n",
    "        angle = np.random.uniform(0, obj_angles) # samples angle from range\n",
    "        angle = round(angle/discretize)*discretize # discretizes to defined range (default 10)\n",
    "        pos = np.array([5*np.cos(np.deg2rad(angle)), 5*np.sin(np.deg2rad(angle))]) # maps to unit circle\n",
    "        \n",
    "        color = np.zeros(shape = 3) # defines total number of colors to choose from\n",
    "        rand_color = random.sample(obj_colors,1) # samples color from range\n",
    "        color[rand_color] = 1.\n",
    "        return pos, color\n",
    "\n",
    "def get_color(color):\n",
    "    if color[0] == 1.:\n",
    "        return 'red'\n",
    "    elif color[1] == 1.:\n",
    "        return 'green'\n",
    "    elif color[2] == 1.:\n",
    "        return 'blue'\n",
    "    elif color[3] == 1.:\n",
    "        return 'yellow'\n",
    "\n",
    "def get_shape(shape):\n",
    "    if shape[0] == 1.:\n",
    "        return 'X'\n",
    "    elif shape[1] == 1.:\n",
    "        return 's'\n",
    "    elif shape[2] == 1.:\n",
    "        return '^'\n",
    "    elif shape[3] == 1.:\n",
    "        return 'd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4e84b28c-d26e-4714-ba45-a65852e67dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_env(env, dist=False):\n",
    "    fig = plt.figure(figsize=(5, 5),facecolor=\"black\")\n",
    "    plt.xlim(-6, 6)\n",
    "    plt.ylim(-6, 6)\n",
    "    plt.axis('off')\n",
    "    plt.scatter(env.pos[0],env.pos[1], marker='o', color='white', s=500) # plots agent\n",
    "    if dist:\n",
    "        plt.scatter(env.obj1_pos[0], env.obj1_pos[1], marker=get_shape(env.obj1_shape), color=get_color(env.obj1_color), s=500) # plots obj1\n",
    "        plt.scatter(env.obj2_pos[0], env.obj2_pos[1], marker=get_shape(env.obj2_shape), color=get_color(env.obj2_color), s=500) # plots obj2\n",
    "    else:\n",
    "        plt.scatter(env.goal_pos[0], env.goal_pos[1], marker=get_shape(env.goal_shape), color=get_color(env.goal_color), s=1000) # plots goal\n",
    "    with io.BytesIO() as buff:\n",
    "        fig.savefig(buff, format='raw')\n",
    "        buff.seek(0)\n",
    "        data = np.frombuffer(buff.getvalue(), dtype=np.uint8)\n",
    "    w, h = fig.canvas.get_width_height()\n",
    "    img = data.reshape((int(h), int(w), -1))\n",
    "    img = img[:,:,:3]\n",
    "    plt.close()\n",
    "    return img\n",
    "\n",
    "def plot_full_state(state, dist=False, hd=False):\n",
    "    if not hd:\n",
    "        fig = plt.figure(figsize=(.5, .5),facecolor=\"black\")\n",
    "        s = 10\n",
    "    else:\n",
    "        fig = plt.figure(figsize=(4, 4),facecolor=\"black\")\n",
    "        s = 400\n",
    "    plt.xlim(-6, 6)\n",
    "    plt.ylim(-6, 6)\n",
    "    plt.axis('off')\n",
    "    plt.scatter(state[0], state[1], marker='o', color='white', s=s) # plots agent\n",
    "    if dist:\n",
    "        plt.scatter(state[2], state[3], marker=get_shape(state[8:12]), color=get_color(state[4:8]), s=s) # plots obj1\n",
    "        plt.scatter(state[12], state[13], marker=get_shape(state[18:22]), color=get_color(state[14:18]), s=s) # plots obj2\n",
    "    else:\n",
    "        plt.scatter(state[22], state[23], marker=get_shape(state[28:32]), color=get_color(state[24:28]), s=s) # plots goal\n",
    "    with io.BytesIO() as buff:\n",
    "        fig.savefig(buff, format='raw')\n",
    "        buff.seek(0)\n",
    "        data = np.frombuffer(buff.getvalue(), dtype=np.uint8)\n",
    "    w, h = fig.canvas.get_width_height()\n",
    "    img = data.reshape((int(h), int(w), -1))\n",
    "    img = img[:,:,:3]\n",
    "    if hd:\n",
    "        plt.savefig('state.pdf')  \n",
    "    plt.close()\n",
    "    return img\n",
    "\n",
    "def plot_img_mask(state):\n",
    "    fig = plt.figure(figsize=(.5, .5),facecolor=\"black\")\n",
    "    plt.xlim(-6, 6)\n",
    "    plt.ylim(-6, 6)\n",
    "    plt.axis('off')\n",
    "    #plt.scatter(state[0], state[1], marker='o', color='white', s=10) # plots agent\n",
    "    #plt.scatter(state[2], state[3], marker=get_shape(state[8:12]), color=get_color(state[4:8]), s=10) # plots obj1\n",
    "    #plt.scatter(state[12], state[13], marker=get_shape(state[18:22]), color=get_color(state[14:18]), s=10) # plots obj1\n",
    "    plt.scatter(state[22], state[23], marker=get_shape(state[28:32]), color=get_color(state[24:28]), s=10) # plots goal\n",
    "    with io.BytesIO() as buff:\n",
    "        fig.savefig(buff, format='raw')\n",
    "        buff.seek(0)\n",
    "        data = np.frombuffer(buff.getvalue(), dtype=np.uint8)\n",
    "    w, h = fig.canvas.get_width_height()\n",
    "    img = data.reshape((int(h), int(w), -1))\n",
    "    img = img[:,:,:3]\n",
    "    img_mask = np.mean(img, axis=2)\n",
    "    img_mask[img_mask > 0] = 1\n",
    "    plt.close()\n",
    "    return img, img_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41fce947-8109-4527-ab95-66e5f2202cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5.  5.  5. -5.  1.  0.  0.  0.  0.  0.  0.  1. 99. 99. 99. 99. 99. 99.\n",
      " 99. 99. 99. 99.  5. -5.  1.  0.  0.  0.  0.  0.  0.  1.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = PointEnvGrid()\n",
    "print(env.reset(agent_pos=[0], obj_pos=[2], obj_colors=[0], obj_shapes=[3], scalar=5, obstacle=False))\n",
    "state = plot_full_state(env.get_full_obs(), dist=False)\n",
    "plt.imshow(state)\n",
    "img, img_mask = plot_img_mask(env.get_full_obs())\n",
    "img_mask = img_mask.reshape((36, 36, 1)) #reshape to 1 channel\n",
    "img_mask = np.repeat(img_mask, 3, axis=2)\n",
    "masked_img = img * img_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2e21d63-eea2-404c-ae55-3c8673ecc8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generates random trajs within specified constraints\n",
    "def gen_trajs(env, num_trajs=1, agent_pos=[0,1,2,3], obj_pos=[0,1,2,3], obj_colors=[0,1,2,3], obj_shapes=[0,1,2,3], scalar=5, obstacle=False):\n",
    "    trajs = []\n",
    "    for traj in range(num_trajs):\n",
    "        env.reset(agent_pos=agent_pos, obj_pos=obj_pos, obj_colors=obj_colors, obj_shapes=obj_shapes, scalar=scalar, obstacle=obstacle)\n",
    "        # rolls out a trajectory towards the goal\n",
    "        traj = {'obs': [],'acts': [],'goal': [], 'gt_masks': []}\n",
    "        delta_vector = env.goal_pos - env.pos\n",
    "        obs = plot_full_state(env.get_full_obs())\n",
    "        for i in range(20):\n",
    "            _, img_mask = plot_img_mask(env.get_full_obs())\n",
    "            act = delta_vector * 0.05 # Go in direction between start and end\n",
    "            traj['obs'].append(obs.copy())\n",
    "            traj['acts'].append(act.copy())\n",
    "            one_hot_goal = np.concatenate([env.goal_color, env.goal_shape])\n",
    "            traj['goal'].append(one_hot_goal)\n",
    "            traj['gt_masks'].append(img_mask)\n",
    "            no, r, d, _ = env.step(act)\n",
    "            obs = plot_full_state(no.copy())\n",
    "        traj['obs'] = np.array(traj['obs'])\n",
    "        traj['acts'] = np.array(traj['acts'])\n",
    "        traj['goal'] = np.array(traj['goal'])\n",
    "        traj['gt_masks'] = np.array(traj['gt_masks'])\n",
    "        #plt.plot(traj['obs'][:, 0], traj['obs'][:, 1]) # plots trajs + goals\n",
    "        trajs.append(traj)\n",
    "    return trajs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2ab75e2-ae6d-48cd-9d19-f1101a7f5f10",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# colors = RGBY\n",
    "# shapes = Xs^d (star, square, triangle, diamond)\n",
    "env = PointEnvGrid()\n",
    "trajs = gen_trajs(env, num_trajs=10, agent_pos=[0], obj_pos=[2], obj_colors=[0], obj_shapes=[3], scalar=5, obstacle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6a66de7-d994-48b5-bdf2-1bb69556f28d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x28ab9b4f0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#import seaborn as sns\n",
    "step = 0\n",
    "traj = 0\n",
    "state = trajs[traj]['obs'][step]\n",
    "gt_mask = trajs[traj]['gt_masks'][step]\n",
    "plt.imshow(gt_mask)\n",
    "gt_mask = gt_mask.reshape((36, 36, 1))\n",
    "gt_mask = np.repeat(gt_mask, 3, axis=2) # duplicate across 3 channels\n",
    "final_state = state * gt_mask # apply mask to full state\n",
    "#plt.imshow(final_state)\n",
    "plt.imshow(trajs[traj]['obs'][step])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "24b2d9d3-2451-4a62-ba47-a0e98581f02f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x17c9b9070>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = PointEnvGrid()\n",
    "env.reset(agent_pos=[0], obj_pos=[2], obj_colors=[2], obj_shapes=[3], scalar=5, obstacle=False)\n",
    "state = plot_full_state(env.get_full_obs(), dist=False, hd=True)\n",
    "plt.imshow(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07ce9082-083c-446a-92e7-47561103291a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNPolicy(\n",
       "  (goal): Sequential(\n",
       "    (0): Linear(in_features=8, out_features=100, bias=True)\n",
       "  )\n",
       "  (conv): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(8, 8), stride=(4, 4))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (7): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    (8): Flatten()\n",
       "    (9): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): Linear(in_features=32, out_features=100, bias=True)\n",
       "  )\n",
       "  (process): Sequential(\n",
       "    (0): Linear(in_features=200, out_features=1000, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=1000, out_features=1296, bias=True)\n",
       "    (3): Sigmoid()\n",
       "  )\n",
       "  (cnntrunk): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(8, 8), stride=(4, 4))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (7): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): Flatten()\n",
       "    (10): Linear(in_features=32, out_features=2, bias=True)\n",
       "  )\n",
       "  (mlptrunk): Sequential(\n",
       "    (0): Linear(in_features=200, out_features=100, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=100, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tasks = len(trajs)\n",
    "\n",
    "goal_size = 8 #384\n",
    "env = PointEnvGrid()\n",
    "act_size = env.action_space.shape[0]\n",
    "hidden_size = 100\n",
    "mask = False\n",
    "\n",
    "policy = CNNPolicy(goal_size, act_size, hidden_size, mask=mask)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "policy.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90e4e3b1-7157-4b74-a7c7-57e878c18936",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] loss: 1.01768696\n",
      "[1,     1] mask loss: 0.00000000\n",
      "[1,     1] action loss: 1.01768696\n",
      "[2,     1] loss: 0.74255264\n",
      "[2,     1] mask loss: 0.00000000\n",
      "[2,     1] action loss: 0.74255264\n",
      "[3,     1] loss: 0.55377311\n",
      "[3,     1] mask loss: 0.00000000\n",
      "[3,     1] action loss: 0.55377311\n",
      "[4,     1] loss: 0.61056107\n",
      "[4,     1] mask loss: 0.00000000\n",
      "[4,     1] action loss: 0.61056107\n",
      "[5,     1] loss: 0.33628407\n",
      "[5,     1] mask loss: 0.00000000\n",
      "[5,     1] action loss: 0.33628407\n",
      "[6,     1] loss: 0.25345594\n",
      "[6,     1] mask loss: 0.00000000\n",
      "[6,     1] action loss: 0.25345594\n",
      "[7,     1] loss: 0.29710016\n",
      "[7,     1] mask loss: 0.00000000\n",
      "[7,     1] action loss: 0.29710016\n",
      "[8,     1] loss: 0.19929144\n",
      "[8,     1] mask loss: 0.00000000\n",
      "[8,     1] action loss: 0.19929144\n",
      "[9,     1] loss: 0.16015851\n",
      "[9,     1] mask loss: 0.00000000\n",
      "[9,     1] action loss: 0.16015851\n",
      "[10,     1] loss: 0.17658108\n",
      "[10,     1] mask loss: 0.00000000\n",
      "[10,     1] action loss: 0.17658108\n",
      "[11,     1] loss: 0.21714731\n",
      "[11,     1] mask loss: 0.00000000\n",
      "[11,     1] action loss: 0.21714731\n",
      "[12,     1] loss: 0.20303857\n",
      "[12,     1] mask loss: 0.00000000\n",
      "[12,     1] action loss: 0.20303857\n",
      "[13,     1] loss: 0.26198405\n",
      "[13,     1] mask loss: 0.00000000\n",
      "[13,     1] action loss: 0.26198405\n",
      "[14,     1] loss: 0.12973852\n",
      "[14,     1] mask loss: 0.00000000\n",
      "[14,     1] action loss: 0.12973852\n",
      "[15,     1] loss: 0.18459727\n",
      "[15,     1] mask loss: 0.00000000\n",
      "[15,     1] action loss: 0.18459727\n",
      "[16,     1] loss: 0.17248897\n",
      "[16,     1] mask loss: 0.00000000\n",
      "[16,     1] action loss: 0.17248897\n",
      "[17,     1] loss: 0.18936639\n",
      "[17,     1] mask loss: 0.00000000\n",
      "[17,     1] action loss: 0.18936639\n",
      "[18,     1] loss: 0.19864109\n",
      "[18,     1] mask loss: 0.00000000\n",
      "[18,     1] action loss: 0.19864109\n",
      "[19,     1] loss: 0.22709355\n",
      "[19,     1] mask loss: 0.00000000\n",
      "[19,     1] action loss: 0.22709355\n",
      "[20,     1] loss: 0.16640221\n",
      "[20,     1] mask loss: 0.00000000\n",
      "[20,     1] action loss: 0.16640221\n",
      "[21,     1] loss: 0.18668577\n",
      "[21,     1] mask loss: 0.00000000\n",
      "[21,     1] action loss: 0.18668577\n",
      "[22,     1] loss: 0.19072112\n",
      "[22,     1] mask loss: 0.00000000\n",
      "[22,     1] action loss: 0.19072112\n",
      "[23,     1] loss: 0.21001074\n",
      "[23,     1] mask loss: 0.00000000\n",
      "[23,     1] action loss: 0.21001074\n",
      "[24,     1] loss: 0.17610115\n",
      "[24,     1] mask loss: 0.00000000\n",
      "[24,     1] action loss: 0.17610115\n",
      "[25,     1] loss: 0.21028812\n",
      "[25,     1] mask loss: 0.00000000\n",
      "[25,     1] action loss: 0.21028812\n",
      "[26,     1] loss: 0.15438052\n",
      "[26,     1] mask loss: 0.00000000\n",
      "[26,     1] action loss: 0.15438052\n",
      "[27,     1] loss: 0.18127072\n",
      "[27,     1] mask loss: 0.00000000\n",
      "[27,     1] action loss: 0.18127072\n",
      "[28,     1] loss: 0.10816477\n",
      "[28,     1] mask loss: 0.00000000\n",
      "[28,     1] action loss: 0.10816477\n",
      "[29,     1] loss: 0.13353378\n",
      "[29,     1] mask loss: 0.00000000\n",
      "[29,     1] action loss: 0.13353378\n",
      "[30,     1] loss: 0.11558054\n",
      "[30,     1] mask loss: 0.00000000\n",
      "[30,     1] action loss: 0.11558054\n",
      "[31,     1] loss: 0.13389973\n",
      "[31,     1] mask loss: 0.00000000\n",
      "[31,     1] action loss: 0.13389973\n",
      "[32,     1] loss: 0.12825285\n",
      "[32,     1] mask loss: 0.00000000\n",
      "[32,     1] action loss: 0.12825285\n",
      "[33,     1] loss: 0.12126267\n",
      "[33,     1] mask loss: 0.00000000\n",
      "[33,     1] action loss: 0.12126267\n",
      "[34,     1] loss: 0.13178083\n",
      "[34,     1] mask loss: 0.00000000\n",
      "[34,     1] action loss: 0.13178083\n",
      "[35,     1] loss: 0.09585379\n",
      "[35,     1] mask loss: 0.00000000\n",
      "[35,     1] action loss: 0.09585379\n",
      "[36,     1] loss: 0.13165854\n",
      "[36,     1] mask loss: 0.00000000\n",
      "[36,     1] action loss: 0.13165854\n",
      "[37,     1] loss: 0.09969532\n",
      "[37,     1] mask loss: 0.00000000\n",
      "[37,     1] action loss: 0.09969532\n",
      "[38,     1] loss: 0.11042430\n",
      "[38,     1] mask loss: 0.00000000\n",
      "[38,     1] action loss: 0.11042430\n",
      "[39,     1] loss: 0.13301447\n",
      "[39,     1] mask loss: 0.00000000\n",
      "[39,     1] action loss: 0.13301447\n",
      "[40,     1] loss: 0.12123481\n",
      "[40,     1] mask loss: 0.00000000\n",
      "[40,     1] action loss: 0.12123481\n",
      "[41,     1] loss: 0.11351813\n",
      "[41,     1] mask loss: 0.00000000\n",
      "[41,     1] action loss: 0.11351813\n",
      "[42,     1] loss: 0.11430611\n",
      "[42,     1] mask loss: 0.00000000\n",
      "[42,     1] action loss: 0.11430611\n",
      "[43,     1] loss: 0.09977722\n",
      "[43,     1] mask loss: 0.00000000\n",
      "[43,     1] action loss: 0.09977722\n",
      "[44,     1] loss: 0.09785601\n",
      "[44,     1] mask loss: 0.00000000\n",
      "[44,     1] action loss: 0.09785601\n",
      "[45,     1] loss: 0.11160694\n",
      "[45,     1] mask loss: 0.00000000\n",
      "[45,     1] action loss: 0.11160694\n",
      "[46,     1] loss: 0.11276735\n",
      "[46,     1] mask loss: 0.00000000\n",
      "[46,     1] action loss: 0.11276735\n",
      "[47,     1] loss: 0.12537129\n",
      "[47,     1] mask loss: 0.00000000\n",
      "[47,     1] action loss: 0.12537129\n",
      "[48,     1] loss: 0.10154863\n",
      "[48,     1] mask loss: 0.00000000\n",
      "[48,     1] action loss: 0.10154863\n",
      "[49,     1] loss: 0.08893336\n",
      "[49,     1] mask loss: 0.00000000\n",
      "[49,     1] action loss: 0.08893336\n",
      "[50,     1] loss: 0.12313552\n",
      "[50,     1] mask loss: 0.00000000\n",
      "[50,     1] action loss: 0.12313552\n",
      "[51,     1] loss: 0.16347341\n",
      "[51,     1] mask loss: 0.00000000\n",
      "[51,     1] action loss: 0.16347341\n",
      "[52,     1] loss: 0.07013103\n",
      "[52,     1] mask loss: 0.00000000\n",
      "[52,     1] action loss: 0.07013103\n",
      "[53,     1] loss: 0.09639815\n",
      "[53,     1] mask loss: 0.00000000\n",
      "[53,     1] action loss: 0.09639815\n",
      "[54,     1] loss: 0.10163806\n",
      "[54,     1] mask loss: 0.00000000\n",
      "[54,     1] action loss: 0.10163806\n",
      "[55,     1] loss: 0.05915558\n",
      "[55,     1] mask loss: 0.00000000\n",
      "[55,     1] action loss: 0.05915558\n",
      "[56,     1] loss: 0.08208223\n",
      "[56,     1] mask loss: 0.00000000\n",
      "[56,     1] action loss: 0.08208223\n",
      "[57,     1] loss: 0.07756743\n",
      "[57,     1] mask loss: 0.00000000\n",
      "[57,     1] action loss: 0.07756743\n",
      "[58,     1] loss: 0.10821587\n",
      "[58,     1] mask loss: 0.00000000\n",
      "[58,     1] action loss: 0.10821587\n",
      "[59,     1] loss: 0.09598885\n",
      "[59,     1] mask loss: 0.00000000\n",
      "[59,     1] action loss: 0.09598885\n",
      "[60,     1] loss: 0.09654574\n",
      "[60,     1] mask loss: 0.00000000\n",
      "[60,     1] action loss: 0.09654574\n",
      "[61,     1] loss: 0.08767723\n",
      "[61,     1] mask loss: 0.00000000\n",
      "[61,     1] action loss: 0.08767723\n",
      "[62,     1] loss: 0.08177637\n",
      "[62,     1] mask loss: 0.00000000\n",
      "[62,     1] action loss: 0.08177637\n",
      "[63,     1] loss: 0.13523775\n",
      "[63,     1] mask loss: 0.00000000\n",
      "[63,     1] action loss: 0.13523775\n",
      "[64,     1] loss: 0.12722032\n",
      "[64,     1] mask loss: 0.00000000\n",
      "[64,     1] action loss: 0.12722032\n",
      "[65,     1] loss: 0.13445704\n",
      "[65,     1] mask loss: 0.00000000\n",
      "[65,     1] action loss: 0.13445704\n",
      "[66,     1] loss: 0.09857982\n",
      "[66,     1] mask loss: 0.00000000\n",
      "[66,     1] action loss: 0.09857982\n",
      "[67,     1] loss: 0.09437086\n",
      "[67,     1] mask loss: 0.00000000\n",
      "[67,     1] action loss: 0.09437086\n",
      "[68,     1] loss: 0.06204396\n",
      "[68,     1] mask loss: 0.00000000\n",
      "[68,     1] action loss: 0.06204396\n",
      "[69,     1] loss: 0.08620771\n",
      "[69,     1] mask loss: 0.00000000\n",
      "[69,     1] action loss: 0.08620771\n",
      "[70,     1] loss: 0.06325389\n",
      "[70,     1] mask loss: 0.00000000\n",
      "[70,     1] action loss: 0.06325389\n",
      "[71,     1] loss: 0.11622743\n",
      "[71,     1] mask loss: 0.00000000\n",
      "[71,     1] action loss: 0.11622743\n",
      "[72,     1] loss: 0.05282490\n",
      "[72,     1] mask loss: 0.00000000\n",
      "[72,     1] action loss: 0.05282490\n",
      "[73,     1] loss: 0.09290058\n",
      "[73,     1] mask loss: 0.00000000\n",
      "[73,     1] action loss: 0.09290058\n",
      "[74,     1] loss: 0.08930755\n",
      "[74,     1] mask loss: 0.00000000\n",
      "[74,     1] action loss: 0.08930755\n",
      "[75,     1] loss: 0.11174593\n",
      "[75,     1] mask loss: 0.00000000\n",
      "[75,     1] action loss: 0.11174593\n",
      "[76,     1] loss: 0.05765297\n",
      "[76,     1] mask loss: 0.00000000\n",
      "[76,     1] action loss: 0.05765297\n",
      "[77,     1] loss: 0.08088622\n",
      "[77,     1] mask loss: 0.00000000\n",
      "[77,     1] action loss: 0.08088622\n",
      "[78,     1] loss: 0.05561874\n",
      "[78,     1] mask loss: 0.00000000\n",
      "[78,     1] action loss: 0.05561874\n",
      "[79,     1] loss: 0.08414803\n",
      "[79,     1] mask loss: 0.00000000\n",
      "[79,     1] action loss: 0.08414803\n",
      "[80,     1] loss: 0.08238736\n",
      "[80,     1] mask loss: 0.00000000\n",
      "[80,     1] action loss: 0.08238736\n",
      "[81,     1] loss: 0.09156377\n",
      "[81,     1] mask loss: 0.00000000\n",
      "[81,     1] action loss: 0.09156377\n",
      "[82,     1] loss: 0.09104662\n",
      "[82,     1] mask loss: 0.00000000\n",
      "[82,     1] action loss: 0.09104662\n",
      "[83,     1] loss: 0.08606084\n",
      "[83,     1] mask loss: 0.00000000\n",
      "[83,     1] action loss: 0.08606084\n",
      "[84,     1] loss: 0.07757650\n",
      "[84,     1] mask loss: 0.00000000\n",
      "[84,     1] action loss: 0.07757650\n",
      "[85,     1] loss: 0.05487391\n",
      "[85,     1] mask loss: 0.00000000\n",
      "[85,     1] action loss: 0.05487391\n",
      "[86,     1] loss: 0.11078860\n",
      "[86,     1] mask loss: 0.00000000\n",
      "[86,     1] action loss: 0.11078860\n",
      "[87,     1] loss: 0.10320816\n",
      "[87,     1] mask loss: 0.00000000\n",
      "[87,     1] action loss: 0.10320816\n",
      "[88,     1] loss: 0.11703677\n",
      "[88,     1] mask loss: 0.00000000\n",
      "[88,     1] action loss: 0.11703677\n",
      "[89,     1] loss: 0.12921023\n",
      "[89,     1] mask loss: 0.00000000\n",
      "[89,     1] action loss: 0.12921023\n",
      "[90,     1] loss: 0.09493250\n",
      "[90,     1] mask loss: 0.00000000\n",
      "[90,     1] action loss: 0.09493250\n",
      "[91,     1] loss: 0.15157071\n",
      "[91,     1] mask loss: 0.00000000\n",
      "[91,     1] action loss: 0.15157071\n",
      "[92,     1] loss: 0.05647580\n",
      "[92,     1] mask loss: 0.00000000\n",
      "[92,     1] action loss: 0.05647580\n",
      "[93,     1] loss: 0.11685704\n",
      "[93,     1] mask loss: 0.00000000\n",
      "[93,     1] action loss: 0.11685704\n",
      "[94,     1] loss: 0.06473689\n",
      "[94,     1] mask loss: 0.00000000\n",
      "[94,     1] action loss: 0.06473689\n",
      "[95,     1] loss: 0.09435318\n",
      "[95,     1] mask loss: 0.00000000\n",
      "[95,     1] action loss: 0.09435318\n",
      "[96,     1] loss: 0.11810844\n",
      "[96,     1] mask loss: 0.00000000\n",
      "[96,     1] action loss: 0.11810844\n",
      "[97,     1] loss: 0.10394993\n",
      "[97,     1] mask loss: 0.00000000\n",
      "[97,     1] action loss: 0.10394993\n",
      "[98,     1] loss: 0.10770093\n",
      "[98,     1] mask loss: 0.00000000\n",
      "[98,     1] action loss: 0.10770093\n",
      "[99,     1] loss: 0.09513255\n",
      "[99,     1] mask loss: 0.00000000\n",
      "[99,     1] action loss: 0.09513255\n",
      "[100,     1] loss: 0.08120192\n",
      "[100,     1] mask loss: 0.00000000\n",
      "[100,     1] action loss: 0.08120192\n",
      "[101,     1] loss: 0.07583848\n",
      "[101,     1] mask loss: 0.00000000\n",
      "[101,     1] action loss: 0.07583848\n",
      "[102,     1] loss: 0.08410362\n",
      "[102,     1] mask loss: 0.00000000\n",
      "[102,     1] action loss: 0.08410362\n",
      "[103,     1] loss: 0.05537083\n",
      "[103,     1] mask loss: 0.00000000\n",
      "[103,     1] action loss: 0.05537083\n",
      "[104,     1] loss: 0.06594656\n",
      "[104,     1] mask loss: 0.00000000\n",
      "[104,     1] action loss: 0.06594656\n",
      "[105,     1] loss: 0.09689169\n",
      "[105,     1] mask loss: 0.00000000\n",
      "[105,     1] action loss: 0.09689169\n",
      "[106,     1] loss: 0.08337350\n",
      "[106,     1] mask loss: 0.00000000\n",
      "[106,     1] action loss: 0.08337350\n",
      "[107,     1] loss: 0.09410629\n",
      "[107,     1] mask loss: 0.00000000\n",
      "[107,     1] action loss: 0.09410629\n",
      "[108,     1] loss: 0.08720720\n",
      "[108,     1] mask loss: 0.00000000\n",
      "[108,     1] action loss: 0.08720720\n",
      "[109,     1] loss: 0.06158549\n",
      "[109,     1] mask loss: 0.00000000\n",
      "[109,     1] action loss: 0.06158549\n",
      "[110,     1] loss: 0.04322160\n",
      "[110,     1] mask loss: 0.00000000\n",
      "[110,     1] action loss: 0.04322160\n",
      "[111,     1] loss: 0.08622827\n",
      "[111,     1] mask loss: 0.00000000\n",
      "[111,     1] action loss: 0.08622827\n",
      "[112,     1] loss: 0.06430118\n",
      "[112,     1] mask loss: 0.00000000\n",
      "[112,     1] action loss: 0.06430118\n",
      "[113,     1] loss: 0.08580582\n",
      "[113,     1] mask loss: 0.00000000\n",
      "[113,     1] action loss: 0.08580582\n",
      "[114,     1] loss: 0.08117533\n",
      "[114,     1] mask loss: 0.00000000\n",
      "[114,     1] action loss: 0.08117533\n",
      "[115,     1] loss: 0.08884867\n",
      "[115,     1] mask loss: 0.00000000\n",
      "[115,     1] action loss: 0.08884867\n",
      "[116,     1] loss: 0.05364596\n",
      "[116,     1] mask loss: 0.00000000\n",
      "[116,     1] action loss: 0.05364596\n",
      "[117,     1] loss: 0.07365846\n",
      "[117,     1] mask loss: 0.00000000\n",
      "[117,     1] action loss: 0.07365846\n",
      "[118,     1] loss: 0.07056262\n",
      "[118,     1] mask loss: 0.00000000\n",
      "[118,     1] action loss: 0.07056262\n",
      "[119,     1] loss: 0.09585014\n",
      "[119,     1] mask loss: 0.00000000\n",
      "[119,     1] action loss: 0.09585014\n",
      "[120,     1] loss: 0.06872930\n",
      "[120,     1] mask loss: 0.00000000\n",
      "[120,     1] action loss: 0.06872930\n",
      "[121,     1] loss: 0.06651443\n",
      "[121,     1] mask loss: 0.00000000\n",
      "[121,     1] action loss: 0.06651443\n",
      "[122,     1] loss: 0.06308389\n",
      "[122,     1] mask loss: 0.00000000\n",
      "[122,     1] action loss: 0.06308389\n",
      "[123,     1] loss: 0.05262879\n",
      "[123,     1] mask loss: 0.00000000\n",
      "[123,     1] action loss: 0.05262879\n",
      "[124,     1] loss: 0.07496414\n",
      "[124,     1] mask loss: 0.00000000\n",
      "[124,     1] action loss: 0.07496414\n",
      "[125,     1] loss: 0.07377314\n",
      "[125,     1] mask loss: 0.00000000\n",
      "[125,     1] action loss: 0.07377314\n",
      "[126,     1] loss: 0.10380080\n",
      "[126,     1] mask loss: 0.00000000\n",
      "[126,     1] action loss: 0.10380080\n",
      "[127,     1] loss: 0.09853749\n",
      "[127,     1] mask loss: 0.00000000\n",
      "[127,     1] action loss: 0.09853749\n",
      "[128,     1] loss: 0.08531229\n",
      "[128,     1] mask loss: 0.00000000\n",
      "[128,     1] action loss: 0.08531229\n",
      "[129,     1] loss: 0.08580953\n",
      "[129,     1] mask loss: 0.00000000\n",
      "[129,     1] action loss: 0.08580953\n",
      "[130,     1] loss: 0.06079643\n",
      "[130,     1] mask loss: 0.00000000\n",
      "[130,     1] action loss: 0.06079643\n",
      "[131,     1] loss: 0.07071815\n",
      "[131,     1] mask loss: 0.00000000\n",
      "[131,     1] action loss: 0.07071815\n",
      "[132,     1] loss: 0.04942987\n",
      "[132,     1] mask loss: 0.00000000\n",
      "[132,     1] action loss: 0.04942987\n",
      "[133,     1] loss: 0.05071353\n",
      "[133,     1] mask loss: 0.00000000\n",
      "[133,     1] action loss: 0.05071353\n",
      "[134,     1] loss: 0.04946408\n",
      "[134,     1] mask loss: 0.00000000\n",
      "[134,     1] action loss: 0.04946408\n",
      "[135,     1] loss: 0.04725122\n",
      "[135,     1] mask loss: 0.00000000\n",
      "[135,     1] action loss: 0.04725122\n",
      "[136,     1] loss: 0.06265046\n",
      "[136,     1] mask loss: 0.00000000\n",
      "[136,     1] action loss: 0.06265046\n",
      "[137,     1] loss: 0.05887353\n",
      "[137,     1] mask loss: 0.00000000\n",
      "[137,     1] action loss: 0.05887353\n",
      "[138,     1] loss: 0.05894317\n",
      "[138,     1] mask loss: 0.00000000\n",
      "[138,     1] action loss: 0.05894317\n",
      "[139,     1] loss: 0.06541959\n",
      "[139,     1] mask loss: 0.00000000\n",
      "[139,     1] action loss: 0.06541959\n",
      "[140,     1] loss: 0.08569790\n",
      "[140,     1] mask loss: 0.00000000\n",
      "[140,     1] action loss: 0.08569790\n",
      "[141,     1] loss: 0.03412138\n",
      "[141,     1] mask loss: 0.00000000\n",
      "[141,     1] action loss: 0.03412138\n",
      "[142,     1] loss: 0.11342452\n",
      "[142,     1] mask loss: 0.00000000\n",
      "[142,     1] action loss: 0.11342452\n",
      "[143,     1] loss: 0.10820502\n",
      "[143,     1] mask loss: 0.00000000\n",
      "[143,     1] action loss: 0.10820502\n",
      "[144,     1] loss: 0.04689149\n",
      "[144,     1] mask loss: 0.00000000\n",
      "[144,     1] action loss: 0.04689149\n",
      "[145,     1] loss: 0.06922999\n",
      "[145,     1] mask loss: 0.00000000\n",
      "[145,     1] action loss: 0.06922999\n",
      "[146,     1] loss: 0.06864531\n",
      "[146,     1] mask loss: 0.00000000\n",
      "[146,     1] action loss: 0.06864531\n",
      "[147,     1] loss: 0.06597020\n",
      "[147,     1] mask loss: 0.00000000\n",
      "[147,     1] action loss: 0.06597020\n",
      "[148,     1] loss: 0.04290925\n",
      "[148,     1] mask loss: 0.00000000\n",
      "[148,     1] action loss: 0.04290925\n",
      "[149,     1] loss: 0.08133044\n",
      "[149,     1] mask loss: 0.00000000\n",
      "[149,     1] action loss: 0.08133044\n",
      "[150,     1] loss: 0.11049309\n",
      "[150,     1] mask loss: 0.00000000\n",
      "[150,     1] action loss: 0.11049309\n",
      "[151,     1] loss: 0.07501208\n",
      "[151,     1] mask loss: 0.00000000\n",
      "[151,     1] action loss: 0.07501208\n",
      "[152,     1] loss: 0.08457272\n",
      "[152,     1] mask loss: 0.00000000\n",
      "[152,     1] action loss: 0.08457272\n",
      "[153,     1] loss: 0.06937220\n",
      "[153,     1] mask loss: 0.00000000\n",
      "[153,     1] action loss: 0.06937220\n",
      "[154,     1] loss: 0.05393165\n",
      "[154,     1] mask loss: 0.00000000\n",
      "[154,     1] action loss: 0.05393165\n",
      "[155,     1] loss: 0.04428480\n",
      "[155,     1] mask loss: 0.00000000\n",
      "[155,     1] action loss: 0.04428480\n",
      "[156,     1] loss: 0.08063392\n",
      "[156,     1] mask loss: 0.00000000\n",
      "[156,     1] action loss: 0.08063392\n",
      "[157,     1] loss: 0.07000185\n",
      "[157,     1] mask loss: 0.00000000\n",
      "[157,     1] action loss: 0.07000185\n",
      "[158,     1] loss: 0.07180630\n",
      "[158,     1] mask loss: 0.00000000\n",
      "[158,     1] action loss: 0.07180630\n",
      "[159,     1] loss: 0.07743924\n",
      "[159,     1] mask loss: 0.00000000\n",
      "[159,     1] action loss: 0.07743924\n",
      "[160,     1] loss: 0.06780352\n",
      "[160,     1] mask loss: 0.00000000\n",
      "[160,     1] action loss: 0.06780352\n",
      "[161,     1] loss: 0.05742624\n",
      "[161,     1] mask loss: 0.00000000\n",
      "[161,     1] action loss: 0.05742624\n",
      "[162,     1] loss: 0.05365693\n",
      "[162,     1] mask loss: 0.00000000\n",
      "[162,     1] action loss: 0.05365693\n",
      "[163,     1] loss: 0.06078089\n",
      "[163,     1] mask loss: 0.00000000\n",
      "[163,     1] action loss: 0.06078089\n",
      "[164,     1] loss: 0.06397723\n",
      "[164,     1] mask loss: 0.00000000\n",
      "[164,     1] action loss: 0.06397723\n",
      "[165,     1] loss: 0.06366354\n",
      "[165,     1] mask loss: 0.00000000\n",
      "[165,     1] action loss: 0.06366354\n",
      "[166,     1] loss: 0.06543927\n",
      "[166,     1] mask loss: 0.00000000\n",
      "[166,     1] action loss: 0.06543927\n",
      "[167,     1] loss: 0.07104649\n",
      "[167,     1] mask loss: 0.00000000\n",
      "[167,     1] action loss: 0.07104649\n",
      "[168,     1] loss: 0.04463693\n",
      "[168,     1] mask loss: 0.00000000\n",
      "[168,     1] action loss: 0.04463693\n",
      "[169,     1] loss: 0.05984686\n",
      "[169,     1] mask loss: 0.00000000\n",
      "[169,     1] action loss: 0.05984686\n",
      "[170,     1] loss: 0.05600602\n",
      "[170,     1] mask loss: 0.00000000\n",
      "[170,     1] action loss: 0.05600602\n",
      "[171,     1] loss: 0.07572030\n",
      "[171,     1] mask loss: 0.00000000\n",
      "[171,     1] action loss: 0.07572030\n",
      "[172,     1] loss: 0.06203815\n",
      "[172,     1] mask loss: 0.00000000\n",
      "[172,     1] action loss: 0.06203815\n",
      "[173,     1] loss: 0.11337774\n",
      "[173,     1] mask loss: 0.00000000\n",
      "[173,     1] action loss: 0.11337774\n",
      "[174,     1] loss: 0.04137275\n",
      "[174,     1] mask loss: 0.00000000\n",
      "[174,     1] action loss: 0.04137275\n",
      "[175,     1] loss: 0.04716564\n",
      "[175,     1] mask loss: 0.00000000\n",
      "[175,     1] action loss: 0.04716564\n",
      "[176,     1] loss: 0.07694132\n",
      "[176,     1] mask loss: 0.00000000\n",
      "[176,     1] action loss: 0.07694132\n",
      "[177,     1] loss: 0.07964510\n",
      "[177,     1] mask loss: 0.00000000\n",
      "[177,     1] action loss: 0.07964510\n",
      "[178,     1] loss: 0.06554426\n",
      "[178,     1] mask loss: 0.00000000\n",
      "[178,     1] action loss: 0.06554426\n",
      "[179,     1] loss: 0.04722721\n",
      "[179,     1] mask loss: 0.00000000\n",
      "[179,     1] action loss: 0.04722721\n",
      "[180,     1] loss: 0.08191428\n",
      "[180,     1] mask loss: 0.00000000\n",
      "[180,     1] action loss: 0.08191428\n",
      "[181,     1] loss: 0.07230543\n",
      "[181,     1] mask loss: 0.00000000\n",
      "[181,     1] action loss: 0.07230543\n",
      "[182,     1] loss: 0.07201266\n",
      "[182,     1] mask loss: 0.00000000\n",
      "[182,     1] action loss: 0.07201266\n",
      "[183,     1] loss: 0.06289997\n",
      "[183,     1] mask loss: 0.00000000\n",
      "[183,     1] action loss: 0.06289997\n",
      "[184,     1] loss: 0.06176137\n",
      "[184,     1] mask loss: 0.00000000\n",
      "[184,     1] action loss: 0.06176137\n",
      "[185,     1] loss: 0.06005027\n",
      "[185,     1] mask loss: 0.00000000\n",
      "[185,     1] action loss: 0.06005027\n",
      "[186,     1] loss: 0.03713071\n",
      "[186,     1] mask loss: 0.00000000\n",
      "[186,     1] action loss: 0.03713071\n",
      "[187,     1] loss: 0.04422630\n",
      "[187,     1] mask loss: 0.00000000\n",
      "[187,     1] action loss: 0.04422630\n",
      "[188,     1] loss: 0.05394562\n",
      "[188,     1] mask loss: 0.00000000\n",
      "[188,     1] action loss: 0.05394562\n",
      "[189,     1] loss: 0.06692579\n",
      "[189,     1] mask loss: 0.00000000\n",
      "[189,     1] action loss: 0.06692579\n",
      "[190,     1] loss: 0.09344630\n",
      "[190,     1] mask loss: 0.00000000\n",
      "[190,     1] action loss: 0.09344630\n",
      "[191,     1] loss: 0.08831597\n",
      "[191,     1] mask loss: 0.00000000\n",
      "[191,     1] action loss: 0.08831597\n",
      "[192,     1] loss: 0.10315397\n",
      "[192,     1] mask loss: 0.00000000\n",
      "[192,     1] action loss: 0.10315397\n",
      "[193,     1] loss: 0.05690112\n",
      "[193,     1] mask loss: 0.00000000\n",
      "[193,     1] action loss: 0.05690112\n",
      "[194,     1] loss: 0.06872417\n",
      "[194,     1] mask loss: 0.00000000\n",
      "[194,     1] action loss: 0.06872417\n",
      "[195,     1] loss: 0.06691784\n",
      "[195,     1] mask loss: 0.00000000\n",
      "[195,     1] action loss: 0.06691784\n",
      "[196,     1] loss: 0.08629213\n",
      "[196,     1] mask loss: 0.00000000\n",
      "[196,     1] action loss: 0.08629213\n",
      "[197,     1] loss: 0.07719515\n",
      "[197,     1] mask loss: 0.00000000\n",
      "[197,     1] action loss: 0.07719515\n",
      "[198,     1] loss: 0.07722624\n",
      "[198,     1] mask loss: 0.00000000\n",
      "[198,     1] action loss: 0.07722624\n",
      "[199,     1] loss: 0.06189304\n",
      "[199,     1] mask loss: 0.00000000\n",
      "[199,     1] action loss: 0.06189304\n",
      "[200,     1] loss: 0.05563983\n",
      "[200,     1] mask loss: 0.00000000\n",
      "[200,     1] action loss: 0.05563983\n",
      "[201,     1] loss: 0.03981365\n",
      "[201,     1] mask loss: 0.00000000\n",
      "[201,     1] action loss: 0.03981365\n",
      "[202,     1] loss: 0.06990796\n",
      "[202,     1] mask loss: 0.00000000\n",
      "[202,     1] action loss: 0.06990796\n",
      "[203,     1] loss: 0.11751654\n",
      "[203,     1] mask loss: 0.00000000\n",
      "[203,     1] action loss: 0.11751654\n",
      "[204,     1] loss: 0.06580625\n",
      "[204,     1] mask loss: 0.00000000\n",
      "[204,     1] action loss: 0.06580625\n",
      "[205,     1] loss: 0.07310597\n",
      "[205,     1] mask loss: 0.00000000\n",
      "[205,     1] action loss: 0.07310597\n",
      "[206,     1] loss: 0.04936926\n",
      "[206,     1] mask loss: 0.00000000\n",
      "[206,     1] action loss: 0.04936926\n",
      "[207,     1] loss: 0.09066195\n",
      "[207,     1] mask loss: 0.00000000\n",
      "[207,     1] action loss: 0.09066195\n",
      "[208,     1] loss: 0.07368844\n",
      "[208,     1] mask loss: 0.00000000\n",
      "[208,     1] action loss: 0.07368844\n",
      "[209,     1] loss: 0.04813759\n",
      "[209,     1] mask loss: 0.00000000\n",
      "[209,     1] action loss: 0.04813759\n",
      "[210,     1] loss: 0.06750177\n",
      "[210,     1] mask loss: 0.00000000\n",
      "[210,     1] action loss: 0.06750177\n",
      "[211,     1] loss: 0.06372044\n",
      "[211,     1] mask loss: 0.00000000\n",
      "[211,     1] action loss: 0.06372044\n",
      "[212,     1] loss: 0.06956859\n",
      "[212,     1] mask loss: 0.00000000\n",
      "[212,     1] action loss: 0.06956859\n",
      "[213,     1] loss: 0.08435931\n",
      "[213,     1] mask loss: 0.00000000\n",
      "[213,     1] action loss: 0.08435931\n",
      "[214,     1] loss: 0.07789251\n",
      "[214,     1] mask loss: 0.00000000\n",
      "[214,     1] action loss: 0.07789251\n",
      "[215,     1] loss: 0.06473601\n",
      "[215,     1] mask loss: 0.00000000\n",
      "[215,     1] action loss: 0.06473601\n",
      "[216,     1] loss: 0.05310310\n",
      "[216,     1] mask loss: 0.00000000\n",
      "[216,     1] action loss: 0.05310310\n",
      "[217,     1] loss: 0.04835635\n",
      "[217,     1] mask loss: 0.00000000\n",
      "[217,     1] action loss: 0.04835635\n",
      "[218,     1] loss: 0.04955989\n",
      "[218,     1] mask loss: 0.00000000\n",
      "[218,     1] action loss: 0.04955989\n",
      "[219,     1] loss: 0.04714933\n",
      "[219,     1] mask loss: 0.00000000\n",
      "[219,     1] action loss: 0.04714933\n",
      "[220,     1] loss: 0.07504291\n",
      "[220,     1] mask loss: 0.00000000\n",
      "[220,     1] action loss: 0.07504291\n",
      "[221,     1] loss: 0.05868164\n",
      "[221,     1] mask loss: 0.00000000\n",
      "[221,     1] action loss: 0.05868164\n",
      "[222,     1] loss: 0.05470438\n",
      "[222,     1] mask loss: 0.00000000\n",
      "[222,     1] action loss: 0.05470438\n",
      "[223,     1] loss: 0.06949563\n",
      "[223,     1] mask loss: 0.00000000\n",
      "[223,     1] action loss: 0.06949563\n",
      "[224,     1] loss: 0.05975249\n",
      "[224,     1] mask loss: 0.00000000\n",
      "[224,     1] action loss: 0.05975249\n",
      "[225,     1] loss: 0.04318478\n",
      "[225,     1] mask loss: 0.00000000\n",
      "[225,     1] action loss: 0.04318478\n",
      "[226,     1] loss: 0.05241720\n",
      "[226,     1] mask loss: 0.00000000\n",
      "[226,     1] action loss: 0.05241720\n",
      "[227,     1] loss: 0.08258954\n",
      "[227,     1] mask loss: 0.00000000\n",
      "[227,     1] action loss: 0.08258954\n",
      "[228,     1] loss: 0.04702535\n",
      "[228,     1] mask loss: 0.00000000\n",
      "[228,     1] action loss: 0.04702535\n",
      "[229,     1] loss: 0.04112112\n",
      "[229,     1] mask loss: 0.00000000\n",
      "[229,     1] action loss: 0.04112112\n",
      "[230,     1] loss: 0.07295753\n",
      "[230,     1] mask loss: 0.00000000\n",
      "[230,     1] action loss: 0.07295753\n",
      "[231,     1] loss: 0.03264979\n",
      "[231,     1] mask loss: 0.00000000\n",
      "[231,     1] action loss: 0.03264979\n",
      "[232,     1] loss: 0.04358761\n",
      "[232,     1] mask loss: 0.00000000\n",
      "[232,     1] action loss: 0.04358761\n",
      "[233,     1] loss: 0.03798736\n",
      "[233,     1] mask loss: 0.00000000\n",
      "[233,     1] action loss: 0.03798736\n",
      "[234,     1] loss: 0.06969960\n",
      "[234,     1] mask loss: 0.00000000\n",
      "[234,     1] action loss: 0.06969960\n",
      "[235,     1] loss: 0.05152779\n",
      "[235,     1] mask loss: 0.00000000\n",
      "[235,     1] action loss: 0.05152779\n",
      "[236,     1] loss: 0.03088290\n",
      "[236,     1] mask loss: 0.00000000\n",
      "[236,     1] action loss: 0.03088290\n",
      "[237,     1] loss: 0.04577758\n",
      "[237,     1] mask loss: 0.00000000\n",
      "[237,     1] action loss: 0.04577758\n",
      "[238,     1] loss: 0.04933139\n",
      "[238,     1] mask loss: 0.00000000\n",
      "[238,     1] action loss: 0.04933139\n",
      "[239,     1] loss: 0.04221977\n",
      "[239,     1] mask loss: 0.00000000\n",
      "[239,     1] action loss: 0.04221977\n",
      "[240,     1] loss: 0.05481068\n",
      "[240,     1] mask loss: 0.00000000\n",
      "[240,     1] action loss: 0.05481068\n",
      "[241,     1] loss: 0.06546940\n",
      "[241,     1] mask loss: 0.00000000\n",
      "[241,     1] action loss: 0.06546940\n",
      "[242,     1] loss: 0.04780536\n",
      "[242,     1] mask loss: 0.00000000\n",
      "[242,     1] action loss: 0.04780536\n",
      "[243,     1] loss: 0.05842849\n",
      "[243,     1] mask loss: 0.00000000\n",
      "[243,     1] action loss: 0.05842849\n",
      "[244,     1] loss: 0.03755873\n",
      "[244,     1] mask loss: 0.00000000\n",
      "[244,     1] action loss: 0.03755873\n",
      "[245,     1] loss: 0.07165295\n",
      "[245,     1] mask loss: 0.00000000\n",
      "[245,     1] action loss: 0.07165295\n",
      "[246,     1] loss: 0.04072077\n",
      "[246,     1] mask loss: 0.00000000\n",
      "[246,     1] action loss: 0.04072077\n",
      "[247,     1] loss: 0.06080635\n",
      "[247,     1] mask loss: 0.00000000\n",
      "[247,     1] action loss: 0.06080635\n",
      "[248,     1] loss: 0.05762322\n",
      "[248,     1] mask loss: 0.00000000\n",
      "[248,     1] action loss: 0.05762322\n",
      "[249,     1] loss: 0.07490225\n",
      "[249,     1] mask loss: 0.00000000\n",
      "[249,     1] action loss: 0.07490225\n",
      "[250,     1] loss: 0.05340070\n",
      "[250,     1] mask loss: 0.00000000\n",
      "[250,     1] action loss: 0.05340070\n",
      "[251,     1] loss: 0.04666641\n",
      "[251,     1] mask loss: 0.00000000\n",
      "[251,     1] action loss: 0.04666641\n",
      "[252,     1] loss: 0.03885693\n",
      "[252,     1] mask loss: 0.00000000\n",
      "[252,     1] action loss: 0.03885693\n",
      "[253,     1] loss: 0.06054909\n",
      "[253,     1] mask loss: 0.00000000\n",
      "[253,     1] action loss: 0.06054909\n",
      "[254,     1] loss: 0.07053270\n",
      "[254,     1] mask loss: 0.00000000\n",
      "[254,     1] action loss: 0.07053270\n",
      "[255,     1] loss: 0.03830291\n",
      "[255,     1] mask loss: 0.00000000\n",
      "[255,     1] action loss: 0.03830291\n",
      "[256,     1] loss: 0.06522124\n",
      "[256,     1] mask loss: 0.00000000\n",
      "[256,     1] action loss: 0.06522124\n",
      "[257,     1] loss: 0.04564311\n",
      "[257,     1] mask loss: 0.00000000\n",
      "[257,     1] action loss: 0.04564311\n",
      "[258,     1] loss: 0.03140402\n",
      "[258,     1] mask loss: 0.00000000\n",
      "[258,     1] action loss: 0.03140402\n",
      "[259,     1] loss: 0.04562312\n",
      "[259,     1] mask loss: 0.00000000\n",
      "[259,     1] action loss: 0.04562312\n",
      "[260,     1] loss: 0.03604349\n",
      "[260,     1] mask loss: 0.00000000\n",
      "[260,     1] action loss: 0.03604349\n",
      "[261,     1] loss: 0.05280532\n",
      "[261,     1] mask loss: 0.00000000\n",
      "[261,     1] action loss: 0.05280532\n",
      "[262,     1] loss: 0.04437698\n",
      "[262,     1] mask loss: 0.00000000\n",
      "[262,     1] action loss: 0.04437698\n",
      "[263,     1] loss: 0.04569267\n",
      "[263,     1] mask loss: 0.00000000\n",
      "[263,     1] action loss: 0.04569267\n",
      "[264,     1] loss: 0.05156509\n",
      "[264,     1] mask loss: 0.00000000\n",
      "[264,     1] action loss: 0.05156509\n",
      "[265,     1] loss: 0.05447430\n",
      "[265,     1] mask loss: 0.00000000\n",
      "[265,     1] action loss: 0.05447430\n",
      "[266,     1] loss: 0.03826683\n",
      "[266,     1] mask loss: 0.00000000\n",
      "[266,     1] action loss: 0.03826683\n",
      "[267,     1] loss: 0.02854014\n",
      "[267,     1] mask loss: 0.00000000\n",
      "[267,     1] action loss: 0.02854014\n",
      "[268,     1] loss: 0.03108699\n",
      "[268,     1] mask loss: 0.00000000\n",
      "[268,     1] action loss: 0.03108699\n",
      "[269,     1] loss: 0.05042776\n",
      "[269,     1] mask loss: 0.00000000\n",
      "[269,     1] action loss: 0.05042776\n",
      "[270,     1] loss: 0.05132549\n",
      "[270,     1] mask loss: 0.00000000\n",
      "[270,     1] action loss: 0.05132549\n",
      "[271,     1] loss: 0.04818834\n",
      "[271,     1] mask loss: 0.00000000\n",
      "[271,     1] action loss: 0.04818834\n",
      "[272,     1] loss: 0.05505938\n",
      "[272,     1] mask loss: 0.00000000\n",
      "[272,     1] action loss: 0.05505938\n",
      "[273,     1] loss: 0.03985375\n",
      "[273,     1] mask loss: 0.00000000\n",
      "[273,     1] action loss: 0.03985375\n",
      "[274,     1] loss: 0.02806509\n",
      "[274,     1] mask loss: 0.00000000\n",
      "[274,     1] action loss: 0.02806509\n",
      "[275,     1] loss: 0.04136351\n",
      "[275,     1] mask loss: 0.00000000\n",
      "[275,     1] action loss: 0.04136351\n",
      "[276,     1] loss: 0.03669348\n",
      "[276,     1] mask loss: 0.00000000\n",
      "[276,     1] action loss: 0.03669348\n",
      "[277,     1] loss: 0.05129503\n",
      "[277,     1] mask loss: 0.00000000\n",
      "[277,     1] action loss: 0.05129503\n",
      "[278,     1] loss: 0.02999404\n",
      "[278,     1] mask loss: 0.00000000\n",
      "[278,     1] action loss: 0.02999404\n",
      "[279,     1] loss: 0.03386576\n",
      "[279,     1] mask loss: 0.00000000\n",
      "[279,     1] action loss: 0.03386576\n",
      "[280,     1] loss: 0.03200759\n",
      "[280,     1] mask loss: 0.00000000\n",
      "[280,     1] action loss: 0.03200759\n",
      "[281,     1] loss: 0.02670345\n",
      "[281,     1] mask loss: 0.00000000\n",
      "[281,     1] action loss: 0.02670345\n",
      "[282,     1] loss: 0.03064937\n",
      "[282,     1] mask loss: 0.00000000\n",
      "[282,     1] action loss: 0.03064937\n",
      "[283,     1] loss: 0.03093490\n",
      "[283,     1] mask loss: 0.00000000\n",
      "[283,     1] action loss: 0.03093490\n",
      "[284,     1] loss: 0.03296060\n",
      "[284,     1] mask loss: 0.00000000\n",
      "[284,     1] action loss: 0.03296060\n",
      "[285,     1] loss: 0.03558739\n",
      "[285,     1] mask loss: 0.00000000\n",
      "[285,     1] action loss: 0.03558739\n",
      "[286,     1] loss: 0.04275852\n",
      "[286,     1] mask loss: 0.00000000\n",
      "[286,     1] action loss: 0.04275852\n",
      "[287,     1] loss: 0.03330676\n",
      "[287,     1] mask loss: 0.00000000\n",
      "[287,     1] action loss: 0.03330676\n",
      "[288,     1] loss: 0.04683093\n",
      "[288,     1] mask loss: 0.00000000\n",
      "[288,     1] action loss: 0.04683093\n",
      "[289,     1] loss: 0.03172239\n",
      "[289,     1] mask loss: 0.00000000\n",
      "[289,     1] action loss: 0.03172239\n",
      "[290,     1] loss: 0.03773675\n",
      "[290,     1] mask loss: 0.00000000\n",
      "[290,     1] action loss: 0.03773675\n",
      "[291,     1] loss: 0.03095594\n",
      "[291,     1] mask loss: 0.00000000\n",
      "[291,     1] action loss: 0.03095594\n",
      "[292,     1] loss: 0.02078385\n",
      "[292,     1] mask loss: 0.00000000\n",
      "[292,     1] action loss: 0.02078385\n",
      "[293,     1] loss: 0.02869418\n",
      "[293,     1] mask loss: 0.00000000\n",
      "[293,     1] action loss: 0.02869418\n",
      "[294,     1] loss: 0.02969147\n",
      "[294,     1] mask loss: 0.00000000\n",
      "[294,     1] action loss: 0.02969147\n",
      "[295,     1] loss: 0.04144008\n",
      "[295,     1] mask loss: 0.00000000\n",
      "[295,     1] action loss: 0.04144008\n",
      "[296,     1] loss: 0.02944280\n",
      "[296,     1] mask loss: 0.00000000\n",
      "[296,     1] action loss: 0.02944280\n",
      "[297,     1] loss: 0.04278295\n",
      "[297,     1] mask loss: 0.00000000\n",
      "[297,     1] action loss: 0.04278295\n",
      "[298,     1] loss: 0.03551439\n",
      "[298,     1] mask loss: 0.00000000\n",
      "[298,     1] action loss: 0.03551439\n",
      "[299,     1] loss: 0.04557534\n",
      "[299,     1] mask loss: 0.00000000\n",
      "[299,     1] action loss: 0.04557534\n",
      "[300,     1] loss: 0.05751588\n",
      "[300,     1] mask loss: 0.00000000\n",
      "[300,     1] action loss: 0.05751588\n",
      "[301,     1] loss: 0.04325921\n",
      "[301,     1] mask loss: 0.00000000\n",
      "[301,     1] action loss: 0.04325921\n",
      "[302,     1] loss: 0.03610919\n",
      "[302,     1] mask loss: 0.00000000\n",
      "[302,     1] action loss: 0.03610919\n",
      "[303,     1] loss: 0.04095384\n",
      "[303,     1] mask loss: 0.00000000\n",
      "[303,     1] action loss: 0.04095384\n",
      "[304,     1] loss: 0.03229697\n",
      "[304,     1] mask loss: 0.00000000\n",
      "[304,     1] action loss: 0.03229697\n",
      "[305,     1] loss: 0.04609533\n",
      "[305,     1] mask loss: 0.00000000\n",
      "[305,     1] action loss: 0.04609533\n",
      "[306,     1] loss: 0.03015357\n",
      "[306,     1] mask loss: 0.00000000\n",
      "[306,     1] action loss: 0.03015357\n",
      "[307,     1] loss: 0.04655556\n",
      "[307,     1] mask loss: 0.00000000\n",
      "[307,     1] action loss: 0.04655556\n",
      "[308,     1] loss: 0.04659330\n",
      "[308,     1] mask loss: 0.00000000\n",
      "[308,     1] action loss: 0.04659330\n",
      "[309,     1] loss: 0.04374938\n",
      "[309,     1] mask loss: 0.00000000\n",
      "[309,     1] action loss: 0.04374938\n",
      "[310,     1] loss: 0.03596739\n",
      "[310,     1] mask loss: 0.00000000\n",
      "[310,     1] action loss: 0.03596739\n",
      "[311,     1] loss: 0.03982601\n",
      "[311,     1] mask loss: 0.00000000\n",
      "[311,     1] action loss: 0.03982601\n",
      "[312,     1] loss: 0.03214748\n",
      "[312,     1] mask loss: 0.00000000\n",
      "[312,     1] action loss: 0.03214748\n",
      "[313,     1] loss: 0.03588470\n",
      "[313,     1] mask loss: 0.00000000\n",
      "[313,     1] action loss: 0.03588470\n",
      "[314,     1] loss: 0.04081399\n",
      "[314,     1] mask loss: 0.00000000\n",
      "[314,     1] action loss: 0.04081399\n",
      "[315,     1] loss: 0.04263207\n",
      "[315,     1] mask loss: 0.00000000\n",
      "[315,     1] action loss: 0.04263207\n",
      "[316,     1] loss: 0.04630562\n",
      "[316,     1] mask loss: 0.00000000\n",
      "[316,     1] action loss: 0.04630562\n",
      "[317,     1] loss: 0.04078556\n",
      "[317,     1] mask loss: 0.00000000\n",
      "[317,     1] action loss: 0.04078556\n",
      "[318,     1] loss: 0.03406505\n",
      "[318,     1] mask loss: 0.00000000\n",
      "[318,     1] action loss: 0.03406505\n",
      "[319,     1] loss: 0.03542186\n",
      "[319,     1] mask loss: 0.00000000\n",
      "[319,     1] action loss: 0.03542186\n",
      "[320,     1] loss: 0.03571229\n",
      "[320,     1] mask loss: 0.00000000\n",
      "[320,     1] action loss: 0.03571229\n",
      "[321,     1] loss: 0.03723007\n",
      "[321,     1] mask loss: 0.00000000\n",
      "[321,     1] action loss: 0.03723007\n",
      "[322,     1] loss: 0.04061201\n",
      "[322,     1] mask loss: 0.00000000\n",
      "[322,     1] action loss: 0.04061201\n",
      "[323,     1] loss: 0.03974402\n",
      "[323,     1] mask loss: 0.00000000\n",
      "[323,     1] action loss: 0.03974402\n",
      "[324,     1] loss: 0.04588295\n",
      "[324,     1] mask loss: 0.00000000\n",
      "[324,     1] action loss: 0.04588295\n",
      "[325,     1] loss: 0.05408634\n",
      "[325,     1] mask loss: 0.00000000\n",
      "[325,     1] action loss: 0.05408634\n",
      "[326,     1] loss: 0.03943921\n",
      "[326,     1] mask loss: 0.00000000\n",
      "[326,     1] action loss: 0.03943921\n",
      "[327,     1] loss: 0.03823451\n",
      "[327,     1] mask loss: 0.00000000\n",
      "[327,     1] action loss: 0.03823451\n",
      "[328,     1] loss: 0.03285868\n",
      "[328,     1] mask loss: 0.00000000\n",
      "[328,     1] action loss: 0.03285868\n",
      "[329,     1] loss: 0.02834609\n",
      "[329,     1] mask loss: 0.00000000\n",
      "[329,     1] action loss: 0.02834609\n",
      "[330,     1] loss: 0.02223652\n",
      "[330,     1] mask loss: 0.00000000\n",
      "[330,     1] action loss: 0.02223652\n",
      "[331,     1] loss: 0.04813833\n",
      "[331,     1] mask loss: 0.00000000\n",
      "[331,     1] action loss: 0.04813833\n",
      "[332,     1] loss: 0.04938072\n",
      "[332,     1] mask loss: 0.00000000\n",
      "[332,     1] action loss: 0.04938072\n",
      "[333,     1] loss: 0.03953929\n",
      "[333,     1] mask loss: 0.00000000\n",
      "[333,     1] action loss: 0.03953929\n",
      "[334,     1] loss: 0.03458633\n",
      "[334,     1] mask loss: 0.00000000\n",
      "[334,     1] action loss: 0.03458633\n",
      "[335,     1] loss: 0.03201963\n",
      "[335,     1] mask loss: 0.00000000\n",
      "[335,     1] action loss: 0.03201963\n",
      "[336,     1] loss: 0.03471764\n",
      "[336,     1] mask loss: 0.00000000\n",
      "[336,     1] action loss: 0.03471764\n",
      "[337,     1] loss: 0.05631673\n",
      "[337,     1] mask loss: 0.00000000\n",
      "[337,     1] action loss: 0.05631673\n",
      "[338,     1] loss: 0.05398484\n",
      "[338,     1] mask loss: 0.00000000\n",
      "[338,     1] action loss: 0.05398484\n",
      "[339,     1] loss: 0.03547793\n",
      "[339,     1] mask loss: 0.00000000\n",
      "[339,     1] action loss: 0.03547793\n",
      "[340,     1] loss: 0.06638204\n",
      "[340,     1] mask loss: 0.00000000\n",
      "[340,     1] action loss: 0.06638204\n",
      "[341,     1] loss: 0.05910180\n",
      "[341,     1] mask loss: 0.00000000\n",
      "[341,     1] action loss: 0.05910180\n",
      "[342,     1] loss: 0.06544786\n",
      "[342,     1] mask loss: 0.00000000\n",
      "[342,     1] action loss: 0.06544786\n",
      "[343,     1] loss: 0.04177786\n",
      "[343,     1] mask loss: 0.00000000\n",
      "[343,     1] action loss: 0.04177786\n",
      "[344,     1] loss: 0.06104334\n",
      "[344,     1] mask loss: 0.00000000\n",
      "[344,     1] action loss: 0.06104334\n",
      "[345,     1] loss: 0.04802699\n",
      "[345,     1] mask loss: 0.00000000\n",
      "[345,     1] action loss: 0.04802699\n",
      "[346,     1] loss: 0.05254844\n",
      "[346,     1] mask loss: 0.00000000\n",
      "[346,     1] action loss: 0.05254844\n",
      "[347,     1] loss: 0.05440072\n",
      "[347,     1] mask loss: 0.00000000\n",
      "[347,     1] action loss: 0.05440072\n",
      "[348,     1] loss: 0.04118864\n",
      "[348,     1] mask loss: 0.00000000\n",
      "[348,     1] action loss: 0.04118864\n",
      "[349,     1] loss: 0.03655217\n",
      "[349,     1] mask loss: 0.00000000\n",
      "[349,     1] action loss: 0.03655217\n",
      "[350,     1] loss: 0.03121142\n",
      "[350,     1] mask loss: 0.00000000\n",
      "[350,     1] action loss: 0.03121142\n",
      "[351,     1] loss: 0.04851107\n",
      "[351,     1] mask loss: 0.00000000\n",
      "[351,     1] action loss: 0.04851107\n",
      "[352,     1] loss: 0.04086616\n",
      "[352,     1] mask loss: 0.00000000\n",
      "[352,     1] action loss: 0.04086616\n",
      "[353,     1] loss: 0.03990870\n",
      "[353,     1] mask loss: 0.00000000\n",
      "[353,     1] action loss: 0.03990870\n",
      "[354,     1] loss: 0.03122154\n",
      "[354,     1] mask loss: 0.00000000\n",
      "[354,     1] action loss: 0.03122154\n",
      "[355,     1] loss: 0.05495259\n",
      "[355,     1] mask loss: 0.00000000\n",
      "[355,     1] action loss: 0.05495259\n",
      "[356,     1] loss: 0.05008972\n",
      "[356,     1] mask loss: 0.00000000\n",
      "[356,     1] action loss: 0.05008972\n",
      "[357,     1] loss: 0.04618564\n",
      "[357,     1] mask loss: 0.00000000\n",
      "[357,     1] action loss: 0.04618564\n",
      "[358,     1] loss: 0.03863064\n",
      "[358,     1] mask loss: 0.00000000\n",
      "[358,     1] action loss: 0.03863064\n",
      "[359,     1] loss: 0.03316809\n",
      "[359,     1] mask loss: 0.00000000\n",
      "[359,     1] action loss: 0.03316809\n",
      "[360,     1] loss: 0.04892050\n",
      "[360,     1] mask loss: 0.00000000\n",
      "[360,     1] action loss: 0.04892050\n",
      "[361,     1] loss: 0.05160774\n",
      "[361,     1] mask loss: 0.00000000\n",
      "[361,     1] action loss: 0.05160774\n",
      "[362,     1] loss: 0.06845157\n",
      "[362,     1] mask loss: 0.00000000\n",
      "[362,     1] action loss: 0.06845157\n",
      "[363,     1] loss: 0.06262080\n",
      "[363,     1] mask loss: 0.00000000\n",
      "[363,     1] action loss: 0.06262080\n",
      "[364,     1] loss: 0.04464044\n",
      "[364,     1] mask loss: 0.00000000\n",
      "[364,     1] action loss: 0.04464044\n",
      "[365,     1] loss: 0.04434368\n",
      "[365,     1] mask loss: 0.00000000\n",
      "[365,     1] action loss: 0.04434368\n",
      "[366,     1] loss: 0.03660722\n",
      "[366,     1] mask loss: 0.00000000\n",
      "[366,     1] action loss: 0.03660722\n",
      "[367,     1] loss: 0.05982497\n",
      "[367,     1] mask loss: 0.00000000\n",
      "[367,     1] action loss: 0.05982497\n",
      "[368,     1] loss: 0.05102967\n",
      "[368,     1] mask loss: 0.00000000\n",
      "[368,     1] action loss: 0.05102967\n",
      "[369,     1] loss: 0.04903223\n",
      "[369,     1] mask loss: 0.00000000\n",
      "[369,     1] action loss: 0.04903223\n",
      "[370,     1] loss: 0.06149329\n",
      "[370,     1] mask loss: 0.00000000\n",
      "[370,     1] action loss: 0.06149329\n",
      "[371,     1] loss: 0.03284110\n",
      "[371,     1] mask loss: 0.00000000\n",
      "[371,     1] action loss: 0.03284110\n",
      "[372,     1] loss: 0.04175272\n",
      "[372,     1] mask loss: 0.00000000\n",
      "[372,     1] action loss: 0.04175272\n",
      "[373,     1] loss: 0.03969910\n",
      "[373,     1] mask loss: 0.00000000\n",
      "[373,     1] action loss: 0.03969910\n",
      "[374,     1] loss: 0.03115598\n",
      "[374,     1] mask loss: 0.00000000\n",
      "[374,     1] action loss: 0.03115598\n",
      "[375,     1] loss: 0.02938767\n",
      "[375,     1] mask loss: 0.00000000\n",
      "[375,     1] action loss: 0.02938767\n",
      "[376,     1] loss: 0.02742931\n",
      "[376,     1] mask loss: 0.00000000\n",
      "[376,     1] action loss: 0.02742931\n",
      "[377,     1] loss: 0.03808800\n",
      "[377,     1] mask loss: 0.00000000\n",
      "[377,     1] action loss: 0.03808800\n",
      "[378,     1] loss: 0.03680163\n",
      "[378,     1] mask loss: 0.00000000\n",
      "[378,     1] action loss: 0.03680163\n",
      "[379,     1] loss: 0.03665572\n",
      "[379,     1] mask loss: 0.00000000\n",
      "[379,     1] action loss: 0.03665572\n",
      "[380,     1] loss: 0.04028542\n",
      "[380,     1] mask loss: 0.00000000\n",
      "[380,     1] action loss: 0.04028542\n",
      "[381,     1] loss: 0.03582189\n",
      "[381,     1] mask loss: 0.00000000\n",
      "[381,     1] action loss: 0.03582189\n",
      "[382,     1] loss: 0.02816934\n",
      "[382,     1] mask loss: 0.00000000\n",
      "[382,     1] action loss: 0.02816934\n",
      "[383,     1] loss: 0.08924950\n",
      "[383,     1] mask loss: 0.00000000\n",
      "[383,     1] action loss: 0.08924950\n",
      "[384,     1] loss: 0.02096699\n",
      "[384,     1] mask loss: 0.00000000\n",
      "[384,     1] action loss: 0.02096699\n",
      "[385,     1] loss: 0.04451029\n",
      "[385,     1] mask loss: 0.00000000\n",
      "[385,     1] action loss: 0.04451029\n",
      "[386,     1] loss: 0.05242264\n",
      "[386,     1] mask loss: 0.00000000\n",
      "[386,     1] action loss: 0.05242264\n",
      "[387,     1] loss: 0.03197365\n",
      "[387,     1] mask loss: 0.00000000\n",
      "[387,     1] action loss: 0.03197365\n",
      "[388,     1] loss: 0.03563522\n",
      "[388,     1] mask loss: 0.00000000\n",
      "[388,     1] action loss: 0.03563522\n",
      "[389,     1] loss: 0.03530885\n",
      "[389,     1] mask loss: 0.00000000\n",
      "[389,     1] action loss: 0.03530885\n",
      "[390,     1] loss: 0.03791147\n",
      "[390,     1] mask loss: 0.00000000\n",
      "[390,     1] action loss: 0.03791147\n",
      "[391,     1] loss: 0.04834715\n",
      "[391,     1] mask loss: 0.00000000\n",
      "[391,     1] action loss: 0.04834715\n",
      "[392,     1] loss: 0.03202031\n",
      "[392,     1] mask loss: 0.00000000\n",
      "[392,     1] action loss: 0.03202031\n",
      "[393,     1] loss: 0.02986225\n",
      "[393,     1] mask loss: 0.00000000\n",
      "[393,     1] action loss: 0.02986225\n",
      "[394,     1] loss: 0.02586607\n",
      "[394,     1] mask loss: 0.00000000\n",
      "[394,     1] action loss: 0.02586607\n",
      "[395,     1] loss: 0.02861304\n",
      "[395,     1] mask loss: 0.00000000\n",
      "[395,     1] action loss: 0.02861304\n",
      "[396,     1] loss: 0.03618244\n",
      "[396,     1] mask loss: 0.00000000\n",
      "[396,     1] action loss: 0.03618244\n",
      "[397,     1] loss: 0.04888061\n",
      "[397,     1] mask loss: 0.00000000\n",
      "[397,     1] action loss: 0.04888061\n",
      "[398,     1] loss: 0.03309881\n",
      "[398,     1] mask loss: 0.00000000\n",
      "[398,     1] action loss: 0.03309881\n",
      "[399,     1] loss: 0.02595191\n",
      "[399,     1] mask loss: 0.00000000\n",
      "[399,     1] action loss: 0.02595191\n",
      "[400,     1] loss: 0.02902716\n",
      "[400,     1] mask loss: 0.00000000\n",
      "[400,     1] action loss: 0.02902716\n",
      "[401,     1] loss: 0.03926049\n",
      "[401,     1] mask loss: 0.00000000\n",
      "[401,     1] action loss: 0.03926049\n",
      "[402,     1] loss: 0.03459577\n",
      "[402,     1] mask loss: 0.00000000\n",
      "[402,     1] action loss: 0.03459577\n",
      "[403,     1] loss: 0.03002974\n",
      "[403,     1] mask loss: 0.00000000\n",
      "[403,     1] action loss: 0.03002974\n",
      "[404,     1] loss: 0.02901652\n",
      "[404,     1] mask loss: 0.00000000\n",
      "[404,     1] action loss: 0.02901652\n",
      "[405,     1] loss: 0.02354930\n",
      "[405,     1] mask loss: 0.00000000\n",
      "[405,     1] action loss: 0.02354930\n",
      "[406,     1] loss: 0.04299120\n",
      "[406,     1] mask loss: 0.00000000\n",
      "[406,     1] action loss: 0.04299120\n",
      "[407,     1] loss: 0.03518295\n",
      "[407,     1] mask loss: 0.00000000\n",
      "[407,     1] action loss: 0.03518295\n",
      "[408,     1] loss: 0.03207206\n",
      "[408,     1] mask loss: 0.00000000\n",
      "[408,     1] action loss: 0.03207206\n",
      "[409,     1] loss: 0.03648044\n",
      "[409,     1] mask loss: 0.00000000\n",
      "[409,     1] action loss: 0.03648044\n",
      "[410,     1] loss: 0.02352756\n",
      "[410,     1] mask loss: 0.00000000\n",
      "[410,     1] action loss: 0.02352756\n",
      "[411,     1] loss: 0.03939528\n",
      "[411,     1] mask loss: 0.00000000\n",
      "[411,     1] action loss: 0.03939528\n",
      "[412,     1] loss: 0.01736179\n",
      "[412,     1] mask loss: 0.00000000\n",
      "[412,     1] action loss: 0.01736179\n",
      "[413,     1] loss: 0.01791976\n",
      "[413,     1] mask loss: 0.00000000\n",
      "[413,     1] action loss: 0.01791976\n",
      "[414,     1] loss: 0.02766659\n",
      "[414,     1] mask loss: 0.00000000\n",
      "[414,     1] action loss: 0.02766659\n",
      "[415,     1] loss: 0.01960017\n",
      "[415,     1] mask loss: 0.00000000\n",
      "[415,     1] action loss: 0.01960017\n",
      "[416,     1] loss: 0.01900669\n",
      "[416,     1] mask loss: 0.00000000\n",
      "[416,     1] action loss: 0.01900669\n",
      "[417,     1] loss: 0.02804745\n",
      "[417,     1] mask loss: 0.00000000\n",
      "[417,     1] action loss: 0.02804745\n",
      "[418,     1] loss: 0.02047511\n",
      "[418,     1] mask loss: 0.00000000\n",
      "[418,     1] action loss: 0.02047511\n",
      "[419,     1] loss: 0.04469839\n",
      "[419,     1] mask loss: 0.00000000\n",
      "[419,     1] action loss: 0.04469839\n",
      "[420,     1] loss: 0.05067071\n",
      "[420,     1] mask loss: 0.00000000\n",
      "[420,     1] action loss: 0.05067071\n",
      "[421,     1] loss: 0.04103599\n",
      "[421,     1] mask loss: 0.00000000\n",
      "[421,     1] action loss: 0.04103599\n",
      "[422,     1] loss: 0.02620541\n",
      "[422,     1] mask loss: 0.00000000\n",
      "[422,     1] action loss: 0.02620541\n",
      "[423,     1] loss: 0.03540452\n",
      "[423,     1] mask loss: 0.00000000\n",
      "[423,     1] action loss: 0.03540452\n",
      "[424,     1] loss: 0.02299351\n",
      "[424,     1] mask loss: 0.00000000\n",
      "[424,     1] action loss: 0.02299351\n",
      "[425,     1] loss: 0.02554182\n",
      "[425,     1] mask loss: 0.00000000\n",
      "[425,     1] action loss: 0.02554182\n",
      "[426,     1] loss: 0.03632309\n",
      "[426,     1] mask loss: 0.00000000\n",
      "[426,     1] action loss: 0.03632309\n",
      "[427,     1] loss: 0.02445549\n",
      "[427,     1] mask loss: 0.00000000\n",
      "[427,     1] action loss: 0.02445549\n",
      "[428,     1] loss: 0.03127066\n",
      "[428,     1] mask loss: 0.00000000\n",
      "[428,     1] action loss: 0.03127066\n",
      "[429,     1] loss: 0.03256588\n",
      "[429,     1] mask loss: 0.00000000\n",
      "[429,     1] action loss: 0.03256588\n",
      "[430,     1] loss: 0.03749684\n",
      "[430,     1] mask loss: 0.00000000\n",
      "[430,     1] action loss: 0.03749684\n",
      "[431,     1] loss: 0.02714574\n",
      "[431,     1] mask loss: 0.00000000\n",
      "[431,     1] action loss: 0.02714574\n",
      "[432,     1] loss: 0.02791394\n",
      "[432,     1] mask loss: 0.00000000\n",
      "[432,     1] action loss: 0.02791394\n",
      "[433,     1] loss: 0.02360116\n",
      "[433,     1] mask loss: 0.00000000\n",
      "[433,     1] action loss: 0.02360116\n",
      "[434,     1] loss: 0.02979891\n",
      "[434,     1] mask loss: 0.00000000\n",
      "[434,     1] action loss: 0.02979891\n",
      "[435,     1] loss: 0.02721144\n",
      "[435,     1] mask loss: 0.00000000\n",
      "[435,     1] action loss: 0.02721144\n",
      "[436,     1] loss: 0.03849299\n",
      "[436,     1] mask loss: 0.00000000\n",
      "[436,     1] action loss: 0.03849299\n",
      "[437,     1] loss: 0.02876945\n",
      "[437,     1] mask loss: 0.00000000\n",
      "[437,     1] action loss: 0.02876945\n",
      "[438,     1] loss: 0.04192231\n",
      "[438,     1] mask loss: 0.00000000\n",
      "[438,     1] action loss: 0.04192231\n",
      "[439,     1] loss: 0.03199125\n",
      "[439,     1] mask loss: 0.00000000\n",
      "[439,     1] action loss: 0.03199125\n",
      "[440,     1] loss: 0.03617931\n",
      "[440,     1] mask loss: 0.00000000\n",
      "[440,     1] action loss: 0.03617931\n",
      "[441,     1] loss: 0.03382931\n",
      "[441,     1] mask loss: 0.00000000\n",
      "[441,     1] action loss: 0.03382931\n",
      "[442,     1] loss: 0.04800539\n",
      "[442,     1] mask loss: 0.00000000\n",
      "[442,     1] action loss: 0.04800539\n",
      "[443,     1] loss: 0.02791001\n",
      "[443,     1] mask loss: 0.00000000\n",
      "[443,     1] action loss: 0.02791001\n",
      "[444,     1] loss: 0.02454818\n",
      "[444,     1] mask loss: 0.00000000\n",
      "[444,     1] action loss: 0.02454818\n",
      "[445,     1] loss: 0.03453718\n",
      "[445,     1] mask loss: 0.00000000\n",
      "[445,     1] action loss: 0.03453718\n",
      "[446,     1] loss: 0.03665822\n",
      "[446,     1] mask loss: 0.00000000\n",
      "[446,     1] action loss: 0.03665822\n",
      "[447,     1] loss: 0.03336813\n",
      "[447,     1] mask loss: 0.00000000\n",
      "[447,     1] action loss: 0.03336813\n",
      "[448,     1] loss: 0.03024954\n",
      "[448,     1] mask loss: 0.00000000\n",
      "[448,     1] action loss: 0.03024954\n",
      "[449,     1] loss: 0.03576104\n",
      "[449,     1] mask loss: 0.00000000\n",
      "[449,     1] action loss: 0.03576104\n",
      "[450,     1] loss: 0.02742919\n",
      "[450,     1] mask loss: 0.00000000\n",
      "[450,     1] action loss: 0.02742919\n",
      "[451,     1] loss: 0.02132084\n",
      "[451,     1] mask loss: 0.00000000\n",
      "[451,     1] action loss: 0.02132084\n",
      "[452,     1] loss: 0.03166450\n",
      "[452,     1] mask loss: 0.00000000\n",
      "[452,     1] action loss: 0.03166450\n",
      "[453,     1] loss: 0.02494033\n",
      "[453,     1] mask loss: 0.00000000\n",
      "[453,     1] action loss: 0.02494033\n",
      "[454,     1] loss: 0.03899675\n",
      "[454,     1] mask loss: 0.00000000\n",
      "[454,     1] action loss: 0.03899675\n",
      "[455,     1] loss: 0.04992583\n",
      "[455,     1] mask loss: 0.00000000\n",
      "[455,     1] action loss: 0.04992583\n",
      "[456,     1] loss: 0.03124295\n",
      "[456,     1] mask loss: 0.00000000\n",
      "[456,     1] action loss: 0.03124295\n",
      "[457,     1] loss: 0.02836964\n",
      "[457,     1] mask loss: 0.00000000\n",
      "[457,     1] action loss: 0.02836964\n",
      "[458,     1] loss: 0.02701324\n",
      "[458,     1] mask loss: 0.00000000\n",
      "[458,     1] action loss: 0.02701324\n",
      "[459,     1] loss: 0.02961681\n",
      "[459,     1] mask loss: 0.00000000\n",
      "[459,     1] action loss: 0.02961681\n",
      "[460,     1] loss: 0.03424577\n",
      "[460,     1] mask loss: 0.00000000\n",
      "[460,     1] action loss: 0.03424577\n",
      "[461,     1] loss: 0.02539872\n",
      "[461,     1] mask loss: 0.00000000\n",
      "[461,     1] action loss: 0.02539872\n",
      "[462,     1] loss: 0.04158827\n",
      "[462,     1] mask loss: 0.00000000\n",
      "[462,     1] action loss: 0.04158827\n",
      "[463,     1] loss: 0.03051794\n",
      "[463,     1] mask loss: 0.00000000\n",
      "[463,     1] action loss: 0.03051794\n",
      "[464,     1] loss: 0.03002698\n",
      "[464,     1] mask loss: 0.00000000\n",
      "[464,     1] action loss: 0.03002698\n",
      "[465,     1] loss: 0.03417497\n",
      "[465,     1] mask loss: 0.00000000\n",
      "[465,     1] action loss: 0.03417497\n",
      "[466,     1] loss: 0.03979028\n",
      "[466,     1] mask loss: 0.00000000\n",
      "[466,     1] action loss: 0.03979028\n",
      "[467,     1] loss: 0.03912912\n",
      "[467,     1] mask loss: 0.00000000\n",
      "[467,     1] action loss: 0.03912912\n",
      "[468,     1] loss: 0.04043684\n",
      "[468,     1] mask loss: 0.00000000\n",
      "[468,     1] action loss: 0.04043684\n",
      "[469,     1] loss: 0.03379752\n",
      "[469,     1] mask loss: 0.00000000\n",
      "[469,     1] action loss: 0.03379752\n",
      "[470,     1] loss: 0.02259053\n",
      "[470,     1] mask loss: 0.00000000\n",
      "[470,     1] action loss: 0.02259053\n",
      "[471,     1] loss: 0.03450442\n",
      "[471,     1] mask loss: 0.00000000\n",
      "[471,     1] action loss: 0.03450442\n",
      "[472,     1] loss: 0.03117365\n",
      "[472,     1] mask loss: 0.00000000\n",
      "[472,     1] action loss: 0.03117365\n",
      "[473,     1] loss: 0.02391470\n",
      "[473,     1] mask loss: 0.00000000\n",
      "[473,     1] action loss: 0.02391470\n",
      "[474,     1] loss: 0.03485735\n",
      "[474,     1] mask loss: 0.00000000\n",
      "[474,     1] action loss: 0.03485735\n",
      "[475,     1] loss: 0.04620710\n",
      "[475,     1] mask loss: 0.00000000\n",
      "[475,     1] action loss: 0.04620710\n",
      "[476,     1] loss: 0.03444689\n",
      "[476,     1] mask loss: 0.00000000\n",
      "[476,     1] action loss: 0.03444689\n",
      "[477,     1] loss: 0.03051239\n",
      "[477,     1] mask loss: 0.00000000\n",
      "[477,     1] action loss: 0.03051239\n",
      "[478,     1] loss: 0.03902808\n",
      "[478,     1] mask loss: 0.00000000\n",
      "[478,     1] action loss: 0.03902808\n",
      "[479,     1] loss: 0.04038545\n",
      "[479,     1] mask loss: 0.00000000\n",
      "[479,     1] action loss: 0.04038545\n",
      "[480,     1] loss: 0.02634976\n",
      "[480,     1] mask loss: 0.00000000\n",
      "[480,     1] action loss: 0.02634976\n",
      "[481,     1] loss: 0.02989877\n",
      "[481,     1] mask loss: 0.00000000\n",
      "[481,     1] action loss: 0.02989877\n",
      "[482,     1] loss: 0.03149791\n",
      "[482,     1] mask loss: 0.00000000\n",
      "[482,     1] action loss: 0.03149791\n",
      "[483,     1] loss: 0.03073082\n",
      "[483,     1] mask loss: 0.00000000\n",
      "[483,     1] action loss: 0.03073082\n",
      "[484,     1] loss: 0.03594173\n",
      "[484,     1] mask loss: 0.00000000\n",
      "[484,     1] action loss: 0.03594173\n",
      "[485,     1] loss: 0.02291067\n",
      "[485,     1] mask loss: 0.00000000\n",
      "[485,     1] action loss: 0.02291067\n",
      "[486,     1] loss: 0.02451604\n",
      "[486,     1] mask loss: 0.00000000\n",
      "[486,     1] action loss: 0.02451604\n",
      "[487,     1] loss: 0.03619779\n",
      "[487,     1] mask loss: 0.00000000\n",
      "[487,     1] action loss: 0.03619779\n",
      "[488,     1] loss: 0.02684924\n",
      "[488,     1] mask loss: 0.00000000\n",
      "[488,     1] action loss: 0.02684924\n",
      "[489,     1] loss: 0.03006411\n",
      "[489,     1] mask loss: 0.00000000\n",
      "[489,     1] action loss: 0.03006411\n",
      "[490,     1] loss: 0.02569215\n",
      "[490,     1] mask loss: 0.00000000\n",
      "[490,     1] action loss: 0.02569215\n",
      "[491,     1] loss: 0.02578226\n",
      "[491,     1] mask loss: 0.00000000\n",
      "[491,     1] action loss: 0.02578226\n",
      "[492,     1] loss: 0.03264283\n",
      "[492,     1] mask loss: 0.00000000\n",
      "[492,     1] action loss: 0.03264283\n",
      "[493,     1] loss: 0.03353926\n",
      "[493,     1] mask loss: 0.00000000\n",
      "[493,     1] action loss: 0.03353926\n",
      "[494,     1] loss: 0.03273235\n",
      "[494,     1] mask loss: 0.00000000\n",
      "[494,     1] action loss: 0.03273235\n",
      "[495,     1] loss: 0.03494700\n",
      "[495,     1] mask loss: 0.00000000\n",
      "[495,     1] action loss: 0.03494700\n",
      "[496,     1] loss: 0.03546339\n",
      "[496,     1] mask loss: 0.00000000\n",
      "[496,     1] action loss: 0.03546339\n",
      "[497,     1] loss: 0.02843255\n",
      "[497,     1] mask loss: 0.00000000\n",
      "[497,     1] action loss: 0.02843255\n",
      "[498,     1] loss: 0.03413058\n",
      "[498,     1] mask loss: 0.00000000\n",
      "[498,     1] action loss: 0.03413058\n",
      "[499,     1] loss: 0.03291216\n",
      "[499,     1] mask loss: 0.00000000\n",
      "[499,     1] action loss: 0.03291216\n",
      "[500,     1] loss: 0.02517791\n",
      "[500,     1] mask loss: 0.00000000\n",
      "[500,     1] action loss: 0.02517791\n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x28b746730>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAtmklEQVR4nO3deXhU5d3/8fd3srGHLSAQdtkRRBDBFVsX3B+3Vq2tWlsf+9TutdX+1LZaW5dWra2tWrW01n2p4oqKyCKCBJB9C4sQtgTCEpZsM/fvjzNzMjOZkACBcMLndV25MnPmzMx9MvA599zbMeccIiISfKGGLoCIiNQPBbqISCOhQBcRaSQU6CIijYQCXUSkkUhvqDdu376969GjR0O9vYhIIM2ePXuLcy4n1WMNFug9evQgLy+vod5eRCSQzOzLmh5Tk4uISCOhQBcRaSQU6CIijYQCXUSkkVCgi4g0Egp0EZFGQoEuItJIBC7QZ60p5rFJ+ewsrWjoooiIHFECF+jvLdjEgxOWMXlZUUMXRUTkiFJroJvZM2ZWaGYLa3jczOxRM8s3s/lmdkL9F7PKtaO6ARCO6MIcIiLx6lJDHweM3cfj5wF9oj83AX8/+GLVzMwAcCjQRUTi1RrozrkpQPE+drkE+LfzzABam1mn+ipgspDFynWo3kFEJJjqow29C7Au7n5BdFs1ZnaTmeWZWV5R0YG1gRteoqvFRUQk0WHtFHXOPemcG+GcG5GTk3L1x1qZX0NXoouIxKuPQF8PdI27nxvddkiYmlxERFKqj0AfD3wrOtplFLDDObexHl43pZA6RUVEUqr1Ahdm9gIwBmhvZgXAr4EMAOfc48C7wPlAPrAHuOFQFdYrj/dbbegiIolqDXTn3NW1PO6A79dbiWoR6xRVk4uISKLAzRQN+TV0JbqISLzABTqxTtGGLYWIyBEncIEe0jAXEZGUAhfo0ThXp6iISJLABbo/bFE1dBGRBIELdA1bFBFJLYCBHptYJCIi8QIY6N5vNbmIiCQKXqBHfyvPRUQSBS7QtZaLiEhqgQt0dYqKiKQWuECvGrbYwAURETnCBC7QY7SWi4hIosAFuj/1X0REEgQu0P02dDWii4gkCF6gR38rzkVEEgUu0NUpKiKSWuAC3XSBCxGRlAIY6FrLRUQklcAFOni1dK3lIiKSKJCBHjJTG7qISJJABrqhNnQRkWTBDHRTG7qISLKABrqaXEREkgUz0FGnqIhIskAGeshMTS4iIkkCGehmWstFRCRZIANdNXQRkeoCGegatigiUl0wA920OJeISLI6BbqZjTWzZWaWb2a3pXi8m5lNMrO5ZjbfzM6v/6ImvJ9GuYiIJKk10M0sDXgMOA8YCFxtZgOTdrsDeNk5Nwy4CvhbfRc0sUyaWCQikqwuNfSRQL5zbpVzrhx4EbgkaR8HtIrezgY21F8Rq9NaLiIi1dUl0LsA6+LuF0S3xfsNcK2ZFQDvAj9I9UJmdpOZ5ZlZXlFR0QEUN/o6qFNURCRZfXWKXg2Mc87lAucDz5pZtdd2zj3pnBvhnBuRk5NzwG9mGrYoIlJNXQJ9PdA17n5udFu8G4GXAZxznwFNgPb1UcBUtB66iEh1dQn0WUAfM+tpZpl4nZ7jk/ZZC3wVwMwG4AX6gbep1CKkYYsiItXUGujOuUrgFmACsARvNMsiM7vbzC6O7vYz4LtmNg94AbjeHcIqtGFqQxcRSZJel52cc+/idXbGb7sr7vZi4JT6LVrNNLFIRKS6QM4U1VouIiLVBTLQQcMWRUSSBTLQQyE0VVREJEkgA12doiIi1QUy0AF2lVU2dBFERI4ogQz0ssowHy0pbOhiiIgcUQIZ6IM6Z5MWsoYuhojIESWQgd63Y0vSTIEuIhIvkIEeMg1bFBFJFshATwtplIuISLJABrqZEVGei4gkCGSgx/pDtYSuiEiVgAa6l+iqpYuIVAlooHu/1Y4uIlIlkIFufg1dgS4iEhPIQI81uSjPRUSqBDTQvd+qoYuIVAlooKtTVEQkWSADPTbrP6xEFxHxBTLQq9rQFegiIjGBDPTYSouqoIuIVAlkoKtTVESkukAGusahi4hUF8hA1zh0EZHqAhro3m/V0EVEqgQ00NUpKiKSLJCBHhuHHlGii4j4AhnoakMXEakumIEeLbXa0EVEqgQz0KM19LACXUTEF8hAj41DL60IN3BJRESOHHUKdDMba2bLzCzfzG6rYZ+vmdliM1tkZs/XbzETpUUD/YJHp1FYUnoo30pEJDDSa9vBzNKAx4CzgQJglpmNd84tjtunD3A7cIpzbpuZdThUBYaqcegAW3eV06Flk0P5diIigVCXGvpIIN85t8o5Vw68CFyStM93gcecc9sAnHOF9VvMRLEmF++9DuU7iYgER10CvQuwLu5+QXRbvL5AXzP71MxmmNnYVC9kZjeZWZ6Z5RUVFR1YiUmsoWuki4iIp746RdOBPsAY4GrgH2bWOnkn59yTzrkRzrkROTk5B/xmobgauoiIeOoS6OuBrnH3c6Pb4hUA451zFc651cByvIA/JEJxpVYNXUTEU5dAnwX0MbOeZpYJXAWMT9rnDbzaOWbWHq8JZlX9FTOR2tBFRKqrNdCdc5XALcAEYAnwsnNukZndbWYXR3ebAGw1s8XAJOBW59zWQ1bouEBXDV1ExFPrsEUA59y7wLtJ2+6Ku+2An0Z/Drn4TlHFuYiIJ5AzRUNqchERqSaQgR4/yMUp0UVEgIAGelp8Db0ByyEiciQJZKAP6pJN17ZNAV3kQkQkJpCB3iIrnfsvHwKohi4iEhPIQAcwYtcVVaSLiECAA90fuqg8FxEBAhzosdmiakIXEfEEONC9305VdBERIMCBHmtyURO6iIgnsIGOOkVFRBIENtD9GnrDFkNE5IgR2ECPdYpq6r+IiCewga42dBGRRIEN9KqJRQ1cEBGRI0RwA92voSvRRUSgMQR6wxZDROSIEdxAR52iIiLxAhvooWjJleciIp7ABro6RUVEEgU20ENay0VEJEFgAz3WKaoauoiIJ8CBrk5REZF4wQ306G/luYiIJ7iBHquhqw1dRAQIcKBrLRcRkUSBDXQNWxQRSRTcQNdaLiIiCRpBoDdsOUREjhSBDfSQOkVFRBLUKdDNbKyZLTOzfDO7bR/7XW5mzsxG1F8Ra3ov77fa0EVEPLUGupmlAY8B5wEDgavNbGCK/VoCPwJm1nchU5bLX23xcLybiMiRry419JFAvnNulXOuHHgRuCTFfvcA9wOl9Vi+GoX8GroSXUQE6hboXYB1cfcLott8ZnYC0NU5986+XsjMbjKzPDPLKyoq2u/CJr6Y90txLiLiOehOUTMLAQ8BP6ttX+fck865Ec65ETk5OQf1viENcxERSVCXQF8PdI27nxvdFtMSGAx8YmZrgFHA+EPdMRpby0WdoiIinroE+iygj5n1NLNM4CpgfOxB59wO51x751wP51wPYAZwsXMu75CUOCqk1RZFRBLUGujOuUrgFmACsAR42Tm3yMzuNrOLD3UBa6JhiyIiidLrspNz7l3g3aRtd9Ww75iDL1btqlZbFBERCPBMUa3lIiKSKLiBHv2tPBcR8QQ20LWWi4hIosAGujpFRUQSBTbQq4YtNnBBRESOEIEN9Bit5SIi4glsoMdq6G/N29DAJREROTIENtAz072iZ6QF9hBEROpVoNPw7IEdqQhHGroYIiJHhEAHenrICGuYi4gIEPRATwtRqUAXEQECHugZIVOTi4hIVKADPT3NqAyrhi4iAoEP9BB7K8LsLqts6KKIiDS4YAd6yNixt4Jh93yoVRdF5KgX8ED3il9eGdFoFxE56gU60DPSzL+t0S4icrQLdKCnxwW6augicrQLdKCnhaqKrxq6iBztAh3oGSHV0EVEYgId6KFQfBu6N8Fo045Syis12UhEjj6BDvT4SUXhiKOwpJRRf5jIj16c24ClEhFpGOkNXYCDEY5U1cQrw46de70JRu8t3NRQRRIRaTCBrqEP7dravx2OOL+pJS2uKUZE5GgR6ED/6oCO/Pmq4wFvlEt5OAxAminQReToE+hAh6orFnk1dK9NXTV0ETkaBT7QY+FdGYlQHl1KN12BLiJHocAHeiy849vQY8MZSyvC5K0p1hh1ETkqBD7QYzX0irDzL3YRC/lHPlrBFY9/xrT8LQ1WPhGRwyXwgR5bcbGsIszHSwuBqpBftmknADv2VjRM4UREDqPAB3osvN+av4FXZxckbCuLNsFUaOaoiBwF6hToZjbWzJaZWb6Z3Zbi8Z+a2WIzm29mE82se/0XNbXYiovFu8v9bbFAj7Wp76kIc8ljn9Ljtne45LFPD1fRREQOq1oD3czSgMeA84CBwNVmNjBpt7nACOfcEOBV4IH6LmhNYu3lu8vC1bbFaugbtu9l3rrtAMxbt11XNxKRRqkuNfSRQL5zbpVzrhx4Ebgkfgfn3CTn3J7o3RlAbv0Ws2axNvT4js8mGWmEI44F63cAsHlHacJztNSuiDRGdQn0LsC6uPsF0W01uRF4L9UDZnaTmeWZWV5RUVHdS7kPvTs092+nh4yzBnTEzFi+ucTfvmHH3oTnaDVGEWmM6rVT1MyuBUYAD6Z63Dn3pHNuhHNuRE5OTr28Z7PMdPp2bAF4NfO0EEQijqemrvb3mbGqOOE5CnQRaYzqEujrga5x93Oj2xKY2VnA/wMuds6V1U/x6qZpRhoQC3Rj2eYSXptTUOP+SzbuPFxFExE5bOoS6LOAPmbW08wygauA8fE7mNkw4Am8MC+s/2LuWxM/0EOE4hbmunBIJ//2iT3a+LeveWoma7bsPnwFFBE5DGoNdOdcJXALMAFYArzsnFtkZneb2cXR3R4EWgCvmNkXZja+hpc7JLKigV4ZdgmBHn97WLc2Cc/ZrslGItLI1OkCF865d4F3k7bdFXf7rHou134pr/SGLH79xK58ubWq5n1G3xzGz9sAwE/O6kt5ZYRx09cA+MsEiIg0FoGfKQqwq8y7UlGfji2IXZXu1nP7cfnwXNq3yCQjzWiamcbpfdv7zzmQQP/Du0t49rM19VFkEZF6F+hL0MV0bNmEheykY6smVEaDOivdO1e9/+PTiUTHnWempfnPib8eaV2EI44npqwC4Juje9RDqUVE6lejqKH/5uJB3HfZcZzQrY0/aSgzGujtW2TRoVUTwOs0jdnfGnppRbj2nQ5SYUkpk5YWaiariByQRhHoXds246qR3UgLmb/2eayGHm9wl2zO6OuNf6/Yzxr63sMQ6D99aR43jJvFyqJdh/y9RKTxaRSBHi+5hh6vSUYad1wwANj/Gvre8kMf6HPXbgNgz2F4LxFpfBpdoIcjXlDHt5fHS49eg7Qysn+BXla575ANRxzb95Tvc5/ahKNNLVprRkQORKPoFI0Xa0pJVUMHyIgut/uTl+bx81fmc9vY/jTPSifsHP2PacnzM9dywyk9GJLbOuF5e8v3fQL45Wvz/fXY3/j+KRzftfU+908ldo7Z3w5bERFohIHeMdoB2iwzdQ09I60q6MMRx73vLqm2T0lpBU9ddyLgrQtTsG0ve8or9/m+E5ds9m+v2Fyy34H+oxfn+he53t9vDyIi0AgD/Vfn9+eknm0Z0aNNysdja6Xvy5TlVUvxPjfzS+58cxG9cprv4xnQK6cFs7/02sAPpAP1zS82+Ld1UWsRORCNrg29U3ZTrh3Vnaz0GmroNTTFxCsPR/y1XuYXeGuqryra99ovIYMTurUGqjo1l28u4fPVxft4lie/sCTh/uOTVzJ+3ga++++8g26XD7LNO0u5682FrN26p/adRaTxBXptMkKJhzznzrNT7jfmj5/w+pwCXpmduGpjZlrqP1lZZYRWTTMwqwr0i/86ja898Rk79lTw9LTVbNlVfRHK4t3l3PtOYrPPp/lb+eELc/lw8WbmREe+HGqTlhZy+d+ns3571drxJaUVrNhcso9npfba7AKufWrmQY8MenfBRv792Zc8//nag3odkaPF0RfoaVVNLhN/dgZtm2cmPN6ySToXRFdp/OnL86o9P759+9nP1nDTv/OoCEcor4yQlR6iaUYae6Pt7aUV3r6vzingnrcX8+xnX1Z7vZ+/Mo9Jy2q+2Me3x+WxdNOhX+73/YWbmP3lNm59peqYv//8XM5+eAqFO0v38czqfvXfBUzL30LBtoOrWceanrTujkjdHHWBnp4W4vqTe3D3JYPondOi2uOXDuvCo1cNI9bUfnLvdnRp3dR/POLgX9PXsHxzCXe+uYgPFm9mbfEeyisjZKan0Swzrdo48sISLxBTdXbWZRLRW/M21LpPTVYV7eL0BybxxtxqS9gniM2ijS/PlOXeiWbr7v1r9oldy7Uuk7cqwxFufnZ2yjVy1Jcgsn+OukAHb6mAb9WwHsvpfXJICxld2nghntumKUmtNPx6/CLueXuxf//ed5aws7SCrPQQTTLSeG7m2oTp+zujS/WmJb9Q9PUBLhraucbyzlvnteM753hq6ipmrNpa477bdpczaWmhv37N0k0lrC3ew49f+mKfI3UqovunGjJ5oBOd6lKzXr99L+8v2sSdby6q9piuLCWyf47KQE92cu92ANx/+XGc0S8nensIZ/bL4aKhnfnBV/qkfF6rJt4goY+XFrJlVzmZ6SG+0r8DAH/9ON/f74XPvUuyxgJqfsF2/jFlFfmFu6gIO0b2bMt3Tu1Z7fUvOK4Tx3XJZlr+FnaVVVJYUsbv3lnCVU/O4Lw/T0255stv31rEDeNm+W3vsZUoAfILa/42EFvUrDxFCNc2ZLPG16xl+OWXW3dzxoOf1Ph4rKYfjjiWbtq5z/LLkcM55/97ksOr0Q1bPBDPXH8iu8sqadciy992cu/2nNzbW263phpxZnoa5w5qx4RF3hj0rPQQvzp/AP/+7Ev+laIJobwyQiTiuPutxeR9uY1HJ66ga9tmtGuRyZDcbP5w2XHc/voCf/+RPdsyrFtrFqzfwbriPQnt/0s27uTNLzawpzxMs8w07nl7MWP6dWDpJq8TM9ZMsjsu0MdNX8MfLjuu2gigdcV7/NE4qWrFG7fvXxt61fHuu8lk4fqqvoH0kLGqaBd5a7Zx5YhczMyfnVsejjD2kakArLnvAsBbiqFpDXMNpGH96r8LeW1OAXPuPJsWWYqYw0l/bbw1XmKXsUtlePc2/HJsf9Zt28PzM70RF1NXeGPVu7VtxtCurZm3bjvllREy0kJ0ym7Cxh3VQ/CdBRt484v1ftiWlFWyeONOvtq/A2bm1+5jBndpRawSft6fp1ZbcOzHL32RcP+1OQX069jSe+1SL8h3lVYF+utz1nP2gI6cd1ynhOdd/vfpFJZ4I3BizSTxq0v+4rX55LTKonXTDFo3y6Rn+32PyY+pjEQo3l1OWWWYZ6at5vpTeib0R5SUVl01qkubptz22gI+X1NMv2NaMrRra79Tuayi6iTjnGPRhp1c+Jdp3HpuP75/5rEp3/vlvHXMXbuNe//nOEJ1mHsg9eeF6KikbbvLFeiHmZpc6iAjLcT3xvRmwDEtqz3WJCONBy4fQvsWWYyONt0kdwbG8mTzzjI/zMfdcKL/eFa0QzItKXiaZ6UndNzGmiD6dWyZsBRwPIf33rtKK6gIR5i7bjsZacYrN48GYEuKDs5YmIPX6RuOuGrj55duLOHSv03nK3/6hB+9OJePl25OfhkAFm3Y4d9+YvIqTrjnQ855aAr/mLqaZ6atTtg3dtI5d1BHKioj/pDJG8bNYl3xHr+Gvrei6qS0s7TS/xby4IRl/tDIdcV7KI47tl+8Op8XPl/Htv0Yx++cI79wlzpj60mq5js5tBTo+yHV//Mz+3eg3zEtybvjLC4c4nVshpPajtOTOkNvPbcfY/p1oHO2t0xBbGx78izW5pnptGmeyS1JtdAHrxxCj3aJteRTjvVOJss3e+3MJaWVPDV1NR8vLSQrPY3jumQD8PKsdSnHw8cr3l2e0PYOXhMPgHPerNYH3l/mP1ZaEeb5mWspKinjgken+dun5XvfYkqir/X0tNV8ml81C7ekrBIzaNs8i7LKiF+bK95dzofR0UMA7y7Y5D9n/LwNCW3pKwpLqAxHOO2BSVz+9+ls3VWWEMg/eXkevxm/iEjEsa54T8p+h0nLCvnX9DV8tKSQsx6azFNTV1EZjvDx0s3sLNW1Zw+Uhpsefgr0/ZDdNCPh/u8v9S6qkSx5tcTkwS2x4LrmpG4AWPRi1sk19JbRTtefndOXm8/o7W9vnpVOq6SydE8K+D99uNxv+//jlUP8JqUF63fw+7iJTKku3HHivR/xf8/NAeDJbw4nMy3kX5s1ZummErbsKqMyHOGRj1bwq/8u4Klpq6q9VrInp1Tt8/a8DTTN8IZ6bt1dzrLNJVw5PJeMNGNzSSkzVlWfZXvnGwt5fPJK//7yzbv8k8/qLbsZ/ruPuP31+f7jU5YXMW76Gp6YsorTHpjkn2Scc3yyrJCtu8q44Z+z+PX4RSyPTqJaVbSbT5YV8e1xedz87Oz9Hod/pJqwaBPPTFvN9JVbat857jkn/f4jFq7fUfvOSSpq6UOR+qdA3w8XDe3M2z84laHRhbeSAz4mI2k2aZolBnUs0GPPjzUbJNfkm0f3M6saRgnQoWWWP8ImpmNLr7Z/Rt8cfnV+fwAmLy+ic3YTxg5ObDMvLCljZ2kF33rmc658/LN9HDEc3611wpDK60Z3555LBgHwyEfL6X/n+37Azl27fZ+v9T/Hd2by8iL+9kk+ZZVh1m/fS7PM9ISVMU/vm0OHlk0Y9+mafb7WlcNzAXhm2mq/6Sbm5byCavvHwjpW65+7bjvX/3MWd42vGi758IfL/dtvz/dOYNNXbuWbT3++z7IExf8+O5u7317MNf+YyX3vLa32LSyVycuL2LyzjFtfnU9lOMLiDTuZX7CdRyeuqHUkS4UWmTvsFOj7IS1kDO6STfe2zQBo1yIz5X6/On8AXVo35dgOLfznxWsRDePsZt7z90Rryelxo1je+eGpCSeGFlleDXtgp1a0bJKRUEN/4bujaB59vHu7Ztx0em+/9l8c14Y8LLrWTChkLFy/gynLi1iQoubVKdoUBNA0I/Hi2qN7t+fSE7ww/c+MtVRGHN8/0/v2kGrdmtP6VD332lHd6da2GQ+8v4zHJq2krDLCzWf08k9od1wwgIuGdqZH+2Z+f8FdFw7kmFZNEl7zlGPb8ZuLBzG0a2t27K2oUzDF+hy27vL+HrFvL+/M3+jvE/tmtWNvBR8vLfS3L0ta/qC8MsKGuCUSYn0OB3OZwsKSUr71zOdMXVHzrOF92VserjFgZ60prtZ/8fjklbw1b4M/6S1my64ylm2qOt5Yp/qyTTt5buZazn90Khf/9VMe+nA5izbsewZzheYRHHYK9ANwxwUD+PNVxzOie+oVHa8Ynsunt32FP105FID2LbP4Y/Q2VE0migXnsdGOz/SQMSQ3m6tHdmVQ5+yE1+zS2juJnDOoIwBXndjNf2x073Z++LeJniSuGek93iyzqib/8v+OZlSvtkxZXuTPHP36iK788CuJbfTHJAV6fKA2y0yjRVa6f3K44ZQe3Hpu/4TnP37tCf7t+BExI3q0ZfKtYwB4dOIKwLt84DmDOjKocytO6+PNAfjtxYP957RqmkHrZonfhG4/bwDNs9I5o28O67fv5d8pllRItqvMC9s3vljPll1lPD11dY37vr9oEzuTav2RiOPGcbO4772lnPnHTzj5vo/JLyzhvQUbOfvhyXztic/4x5RV7Cmv5NGJK/zF3epq5qpipiwvSmhOqqvSijDD7vmAm56d7W/bU17J1mhfyb3vLOHuuIlwMbe/voCTfj+RdcVVSzR87z+zOfeRKSzasIOKcMRvaou46rOaazuR3v/+Un77VvUJY7Ey7++1c51zvDVvw37/bWuzccfeRnPZR40pOgAdWjXhkuO71Lpfv2Nacs1J3bh4aGdG9WrH5Sd0YWdppd/UMqJ7G9665VT6dPQC3cwYf8upKV9rZM+2zLj9q3Ro6Y2VT/52cMnxnSmvjHDZCV389/76iK6MiU6UAq8pqGubZsyg2G+WuOPCASzasJNH4yZC5cSNx09PCzGiR1v/fmyd+XHXj+SlvLX8T9Lf4bXvjU7osO0W/TYTY2bktMyiKDqyZky/HLLS03jnh6f5+8S+2YDXPDWwcyt/ZAtAm+j6O5cc35lHJ67wh8k9ds0JZDfN4NqnZ1b7+22Jvt+qot2M+N1H1R6P+dnZfflTXNNLzF8+zmfi0kImxtXcJy0tSlhPf+POUqYs38JDHy4nv3AXj149LOE18tYU89qcAu64YKDfnBbzwWJv1FBF2FERjvDPT1ezqmg3Wekhbjy1F93aeX/H/MIS3vxiAzed3ouWTbx/R+8u2EhpRcT/VjF37TYu/dt0mmSEmHvnOQnfHK4cnpuw4Jxz8NnKrVz4l2nceGpPf1byNf+Yyahe3ufeoWUWhSVlfLYycT5GclNXsjlrtzNn7XbuunAgP37pC1YV7Wb8LadQVFLGqD9M5LqTe/Driwbt8zXiTV5exA9emMuwbq357/+dUufnPfTBMqbmb+Hl/x1drTkU4KK/TGPLrnJW/f78Og1xXbh+B1NXbOGm03tV+/bd0BToh1CTjDR+f+lx/n0zS2h3NzOOy81O9dSU4mvO7ZtnRV/Du9+6WSbfPb2X/3hGWoj7rxhS7TV+eV5/zhrYkc9WbqW0IkyLrPSE8e3Hd23NdSf38AMGvCajkT3b8vnqYr+2nN0sg5tOr+qoPbFHG2at2Ua3ts39y/yBF9j5hbvoEVdTL4sGzGl92te4zHF20wx27K2gRVY6v75wEBcN7UyaGfMLtvujg3rntODxa4fz1rwN7C6v5Ix+OTStYT7BZykmh507qKM/KSx2nDec2jNloD/8UfVtseaqcwZ25IPFm3l1dgGvz/HCMrn2+of3lvDEZK9D+LzBnTi9bw7b95TzyEcreHv+BrZEm4I+X13MlY9/xhfrtvvP/ddnX/LiTaNIDxlXRPs8tuwq4w+XDWHmqq3c+mpVJ3A44vwln0srIizcsIMde6tG6nSOmwfw3dN68o+pq/njB8vYsbeCh+KOe8feCiYs2kz7Flk8evUwrnpyBiuio4t+MbYfD7y/jB++MJd/fXukP1x32+7ylJPwSsoq/fX+d5VVsnzzLiIOnpuxll+O7c/O0go6tGzCk1NW8vqc9bxy82gy00MUlZSR26aqQvCXaKVj7trtlFaE9zl3pLQizB1vLOSCIZ38ykpRSVnC8YP3zSv2t9+xt4I2zTNZULCD1+YU8PNz+/Hl1t2sK95LTstMhnf3TnA/f2UeSzeVMLRrNtt2VzC8e5uE/5sNSYEeUNnNMvjNRQPplWKBsX1p3yKLcwcdw7mDjvG3xYfqG9/3aj73XXacv74LwF+vGcbiDTtTLmgG8MQ3R7Bh+15yWmYRjjiG5mYztGtrju3QkvsuTzyxlEbbVr9xUvcay/mV/h3479z1dGiVRXazDM7s5026Or1vTsJ+Ywcfw9jBxyRsu++y48humsHW3eXc8cbClK8/pl8OvxjbnyG5rXlwgjcE84aTe9AiK52LhnaucUG075/Zm++c2oth93zoN0f85Oy+bN1d7l/gBLw27XDEkRYySkor/DAH+NYzn/P8d05i085Sxk1f42/v0rop67fvTQjzbm2bsbZ4D1c9OSOhHC98vo62zTN5bJLXRJOZFqI8HOGrf/qES4fl+vvd+cbChEluPdo347Q+7Rndux3/e3pvxk1fkzAPAbyO7+c/X0tF2DGmXw4je7TlrgsH+s02V53YjQfeX0Z5OMI1T83ghe+O4icvfZFyMh3Ad8bl+bcLS8oYP89r7stIM255fi4fLdnMhz85nb98nE9JaSXffPpz/28w9Rdn0jX6LS9+ktwvXp3P9af0YMKiTXz3tF788tX5nNizLTef0ZtPlhVy/T9nAfiXhQT4NH8Lc9Zu56wBHVhXvIcrR3T1O7/Bm12dkR7i9v/OZ+H6nbRtnumf5DLSjAk/Pp22zTP9b4vX/MP7Jvi1Ebncd9kQxk1fw4BOrZi+cgtXDM+le7vmOOcorYgwaVkhLbLS6d+pJR1aHrrwt/1tx6ovI0aMcHl5ebXvKIfcuuI9nPbAJIZ3b8Nr3zv5kL/f8zPXMn3lFh75+vEJtfl4e8vDrNu2h74dq0/m2h/vLtjoD8G8dlQ3/jNjLYM6t/KbeNZu3cMjE5fzvTN6c2yHFpgZRSVlTFleRLd2zZhfsMNfiK1Vk3Qm/XwM7VpkMfaRKf5/7M9/9VVmrC7mhy/MTXjvDi2zGDv4GN78YkNCLRmgR7tmHJfbOuHE8Z8bT+Ku8QsTLqbywBVD+OVr8/0Zww9eMYSsjDT/vbq3a8ZPz+7LmL4duPPNhf5JJis9xOje7fgkujRz7GSRfL3b6Su3+MF01oCOfLRkM/83pjebdpby+pz13HhqT+68cCAV4QjffHomo3q14//GHEvfO97zX6NNswy27alIaEqryZXDc/ls1VYKtu1N2J7TMouyinC1vouXbhrFSb28bwCj/zCRYzu08Gdpp/LFXWfzgxfm7nOfmOQT9+/+ZzCPTlxR7QQ3uEurhGUqkqWFjP7HtEzoJO6c3YQ/fe14fvnafH9kVcw3TurGvXHf3PeXmc12zo1I+ZgCXcBrn+zXseUR89WxvmzdVcafPlzON0d1JyMtxEV/mcavzu/PN2tYbTOVX7w6j+LdFTx1XdX/oWdnfMmdbyykaUYaC35zDmu27uGshybTvkUmY/p1SKgZZqaFuPfSwWzfU8FrcwoS+gNiptx6pt9O/tTUVfwuOldg8q1j6N6uOb99axEtm2Tw07P7UhGOMHHJZgZ1zia3TVN/HkNpRZiR937kh+LC357LnW8spHlWGnddOIiKcKRa2z3Ara/MI79oF3dcMIBbnp/L/ZcPYWjX1jwzbTVXDM/1a8jxnpi8kiYZaTw4YRm7yirJSDNW3Hs+r+StS2gCOq1Pey4a0pkz+3fg/Een+oF/cu92TF9ZvXmmfYtMvwkEvG8o3ds1o6S0ki/Wbee60d35Vx06wWMGd2nF4M7ZvDjLWyCvb8cW/uS7urhieC6/v/S4hBMYeP038ZeN3JezB3YkZCQ0733009M5tsOBVVYU6CL1rKS0gvHzNnDhcZ3JbpaBc44np6zihO5tGJKbzdZd5Tw9bTUbd+zlsWtO8EMXYNqKLX7H7ds/8DrBB3dJ7EsJRxzb95QnLBhXF1OWF/GtZ7xx87GFzA6lXWWVPPTBcrq3a8Z1J/dgV1kl9723hP/MWFutDHvLw4z54yQ6ZTdl3A0n8u1xsygpreSVm0fz4IRlPDdzLdef3IOzB3bkG09V79gGuOXMY1mycWdC5zTAW7ecyg3jPvdPBl8bkct5x3XizH4diEQcZz88mZVFu3nuOycxuHM2t7wwx6/Fj+rVlgcuH8r97y8F84ayfuOkbtx8Rm86t25KWsgY+tsPEr5lrfz9+VSEI7w1bwOPTcrnb98YznMzv+S5mYlX1xqSm834W06lIhzhuRlfsquskj9+sJy7L6l5Ce/aKNBFjiDbdpdz1kOT+dqJXfnl2P61P2E/3fvOYrq2bXbAgXGwyirDnPvwFM4a0JE7LhxY5+e8Nns9Zw3oQNvmmYybvsb/lhLvr9cM48IhnZm5aivzC3Zw7qBjcDi6t2tOOOJ4bXYBJx/bLqEzFbxvLys272Jwl1aYGeuK93DDuFlcM7IbV43smjC8d295mCYZoYST8OTlRUxbUcTFQ7tQHo4wPMWQ5RWbS3jji/VcdkIuvXNaEI44QkbC64B3rdzmWekHvHDZQQe6mY0F/gykAU855+5LejwL+DcwHNgKfN05t2Zfr6lAF5GaOOd4+MPl7Cyt5KwB3tyLkT3bJswqPlrtK9BrPUWYWRrwGHA2UADMMrPxzrn4mQo3Atucc8ea2VXA/cDXD77oInI0MjN+ek6/hi5G4NTldDcSyHfOrXLOlQMvApck7XMJ8K/o7VeBr1ry9wwRETmk6hLoXYB1cfcLottS7uOcqwR2AO2SX8jMbjKzPDPLKyo6sDUrREQktcPaIOWce9I5N8I5NyInJ6f2J4iISJ3VJdDXA13j7udGt6Xcx8zSgWy8zlERETlM6hLos4A+ZtbTzDKBq4DxSfuMB66L3r4C+Ng11HhIEZGjVK2jXJxzlWZ2CzABb9jiM865RWZ2N5DnnBsPPA08a2b5QDFe6IuIyGFUp5Htzrl3gXeTtt0Vd7sUuLJ+iyYiIvtDo/RFRBqJBpv6b2ZFQN1X2UnUHqj7lW4bBx3z0UHHfHQ4mGPu7pxLOUywwQL9YJhZXk1TXxsrHfPRQcd8dDhUx6wmFxGRRkKBLiLSSAQ10J9s6AI0AB3z0UHHfHQ4JMccyDZ0ERGpLqg1dBERSaJAFxFpJAIX6GY21syWmVm+md3W0OWpL2bW1cwmmdliM1tkZj+Kbm9rZh+a2Yro7zbR7WZmj0b/DvPN7ISGPYIDY2ZpZjbXzN6O3u9pZjOjx/VSdP0gzCwrej8/+niPBi34ATKz1mb2qpktNbMlZjb6KPiMfxL9N73QzF4wsyaN8XM2s2fMrNDMFsZt2+/P1syui+6/wsyuS/VeNQlUoMddPek8YCBwtZnV7aKFR75K4GfOuYHAKOD70WO7DZjonOsDTIzeB+9v0Cf6cxPw98Nf5HrxIyD+4pH3Aw87544FtuFdDQvirooFPBzdL4j+DLzvnOsPDMU79kb7GZtZF+CHwAjn3GC89aBiVzVrbJ/zOGBs0rb9+mzNrC3wa+AkvIsL/Tp2EqgT51xgfoDRwIS4+7cDtzd0uQ7Rsb6Jd9m/ZUCn6LZOwLLo7SeAq+P29/cLyg/eUswTga8AbwOGN3suPfnzxlscbnT0dnp0P2voY9jP480GVieXu5F/xrGL37SNfm5vA+c21s8Z6AEsPNDPFrgaeCJue8J+tf0EqoZO3a6eFHjRr5nDgJlAR+fcxuhDm4CO0duN4W/xCPALIBK93w7Y7ryrXkHiMdXpqlhHuJ5AEfDPaDPTU2bWnEb8GTvn1gN/BNYCG/E+t9k07s853v5+tgf1mQct0Bs9M2sBvAb82Dm3M/4x552yG8U4UzO7ECh0zs1u6LIcRunACcDfnXPDgN1UfQUHGtdnDBBtLrgE72TWGWhO9WaJo8Lh+GyDFuh1uXpSYJlZBl6YP+ecez26ebOZdYo+3gkojG4P+t/iFOBiM1uDd+Hxr+C1L7eOXvUKEo+pMVwVqwAocM7NjN5/FS/gG+tnDHAWsNo5V+ScqwBex/vsG/PnHG9/P9uD+syDFuh1uXpSIJmZ4V0oZIlz7qG4h+KvBnUdXtt6bPu3or3lo4AdcV/tjnjOududc7nOuR54n+PHzrlvAJPwrnoF1Y830FfFcs5tAtaZWb/opq8Ci2mkn3HUWmCUmTWL/huPHXOj/ZyT7O9nOwE4x8zaRL/dnBPdVjcN3YlwAJ0O5wPLgZXA/2vo8tTjcZ2K93VsPvBF9Od8vPbDicAK4COgbXR/wxvxsxJYgDeKoMGP4wCPfQzwdvR2L+BzIB94BciKbm8SvZ8ffbxXQ5f7AI/1eCAv+jm/AbRp7J8x8FtgKbAQeBbIaoyfM/ACXj9BBd63sRsP5LMFvh09/nzghv0pg6b+i4g0EkFrchERkRoo0EVEGgkFuohII6FAFxFpJBToIiKNhAJdRKSRUKCLiDQS/x/bdRJLXfCFIwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_epochs = 500\n",
    "batch_size = 10\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(list(policy.parameters()))\n",
    "\n",
    "losses = []\n",
    "\n",
    "idxs = np.array(range(len(trajs)))\n",
    "\n",
    "num_batches = len(idxs) // batch_size\n",
    "# Train the model with regular SGD\n",
    "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "    np.random.shuffle(idxs)\n",
    "    running_loss = 0.0\n",
    "    for i in range(num_batches):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        t_idx = np.random.randint(len(trajs), size=(batch_size,)) # Indices of traj\n",
    "        t_idx_pertraj = np.random.randint(20, size=(batch_size,)) # Indices of timesteps in traj\n",
    "        t_states = np.concatenate([trajs[c_idx]['obs'][t_idx][None] for (c_idx, t_idx) in zip(t_idx, t_idx_pertraj)])\n",
    "        t_goals = np.concatenate([trajs[c_idx]['goal'][t_idx][None] for (c_idx, t_idx) in zip(t_idx, t_idx_pertraj)])\n",
    "        t_gt_masks = np.concatenate([trajs[c_idx]['gt_masks'][t_idx][None] for (c_idx, t_idx) in zip(t_idx, t_idx_pertraj)])\n",
    "        t_actions = np.concatenate([trajs[c_idx]['acts'][t_idx][None] for (c_idx, t_idx) in zip(t_idx, t_idx_pertraj)])\n",
    "   \n",
    "        t_states = torch.Tensor(t_states).float().to(device)\n",
    "        t_goals = torch.Tensor(t_goals).float().to(device)\n",
    "        #t_goals = torch.Tensor(lang_model.encode(t_goals.ravel())).float().to(device) # embeds goal through language model dim:384\n",
    "        t_gt_masks = torch.Tensor(t_gt_masks).float().to(device)\n",
    "        t_actions = torch.Tensor(t_actions).float().to(device)\n",
    "        \n",
    "        if mask:\n",
    "            a_preds, masked_state_preds, img_mask_preds = policy(t_goals, t_states, t_gt_masks)\n",
    "            mask_loss = 5e-6*masked_state_preds.sum()\n",
    "        else:\n",
    "            a_preds = policy(t_goals, t_states, t_gt_masks)[0]\n",
    "        \n",
    "        action_loss = torch.mean(torch.linalg.norm(a_preds - t_actions, dim=-1)) # supervised learning loss\n",
    "        #construal_loss = 1e-1*((state_mask_preds - t_construals)*(state_mask_preds - t_construals)).sum() # MSE supervised construal loss\n",
    "        if mask:\n",
    "            loss = action_loss + mask_loss\n",
    "        else:\n",
    "            loss = action_loss\n",
    "            mask_loss = 0\n",
    "        \n",
    "        loss.backward()\n",
    "        #print(policy.conv[0].weight.grad)\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 0:\n",
    "            print('[%d, %5d] loss: %.8f' %\n",
    "                  (epoch + 1, i + 1, running_loss))\n",
    "            print('[%d, %5d] mask loss: %.8f' %\n",
    "                  (epoch + 1, i + 1, mask_loss))\n",
    "            print('[%d, %5d] action loss: %.8f' %\n",
    "                  (epoch + 1, i + 1, action_loss))\n",
    "            losses.append(running_loss)\n",
    "            running_loss = 0.0\n",
    "        losses.append(loss.item())\n",
    "\n",
    "print('Finished Training')\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1c5871ec-78d6-4312-8448-38ce3413b543",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['go to the red d']\n",
      "Average dist to goal:  -0.20946567557209889\n",
      "Average std:  0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "policy.eval()\n",
    "num_test_trajs = 1\n",
    "obstacle = False\n",
    "# sets sampling for angles and colors\n",
    "agent_pos=[0]\n",
    "obj_pos=[2,3]\n",
    "obj_colors=[0,1]\n",
    "obj_shapes=[1,3]\n",
    "scalar=5\n",
    "\n",
    "dist_to_goals = []\n",
    "\n",
    "for i in range(num_test_trajs):\n",
    "    env.reset(agent_pos, obj_pos, obj_colors, obj_shapes, scalar, obstacle)\n",
    "    one_hot_goal = np.concatenate([env.goal_color, env.goal_shape])\n",
    "    goal = torch.Tensor(one_hot_goal[None]).to(device)\n",
    "    #goal = torch.Tensor(lang_model.encode(env.goal)).to(device)\n",
    "    obs = plot_full_state(env.get_full_obs())\n",
    "    _, gt_mask = plot_img_mask(env.get_full_obs())\n",
    "    \n",
    "    traj = {'obs': [],'acts': [], 'true_goal': [], 'agent_pos': [], 'masked_states': [], 'masks': []}\n",
    "    for i in range(20):\n",
    "        state = torch.Tensor(obs[None]).to(device)\n",
    "        gt_mask = torch.Tensor(gt_mask[None]).to(device)\n",
    "        if mask:\n",
    "            action, masked_state, img_mask = policy(goal,state,gt_mask)\n",
    "            action = action.cpu().detach().numpy()[0]\n",
    "            masked_state = masked_state.cpu().detach().numpy()[0].transpose((1,2,0))\n",
    "            img_mask = img_mask.cpu().detach().numpy()[0].transpose((1,2,0))\n",
    "            traj['masked_states'].append(masked_state)\n",
    "            traj['masks'].append(img_mask)\n",
    "        else:\n",
    "            action = policy(goal,state,gt_mask)[0].cpu().detach().numpy()[0]\n",
    "        traj['obs'].append(obs.copy())\n",
    "        traj['acts'].append(action.copy())\n",
    "        traj['true_goal'].append(env.goal)\n",
    "        traj['agent_pos'].append(env.pos.tolist())\n",
    "        no, r, d, _ = env.step(action)\n",
    "        obs = plot_full_state(env.get_full_obs())\n",
    "        _, gt_mask = plot_img_mask(env.get_full_obs())\n",
    "    traj['obs'] = np.array(traj['obs'])\n",
    "    traj['acts'] = np.array(traj['acts'])\n",
    "    traj['true_goal'] = np.array(traj['true_goal'])\n",
    "    traj['agent_pos'] = np.array(traj['agent_pos'])\n",
    "    traj['masked_states'] = np.array(traj['masked_states'])\n",
    "    traj['masks'] = np.array(traj['masks'])\n",
    "    dist_to_goals.append(r.copy())\n",
    "    #print(\"Final dist to goal: \", r)\n",
    "    fig = plt.figure(figsize=(4, 4),facecolor=\"black\")\n",
    "    plt.xlim(-6, 6)\n",
    "    plt.ylim(-6, 6)\n",
    "    colors = sns.color_palette(\"hls\", 10)\n",
    "    plt.scatter(traj['agent_pos'][0][0], traj['agent_pos'][0][1], marker='o', color='white', s=400) # plots obj1\n",
    "    plt.scatter(env.obj1_pos[0], env.obj1_pos[1], marker=get_shape(env.obj1_shape), color=get_color(env.obj1_color), s=400) # plots obj1\n",
    "    plt.scatter(env.obj2_pos[0], env.obj2_pos[1], marker=get_shape(env.obj2_shape), color=get_color(env.obj2_color), s=400) # plots obj1\n",
    "    #plt.scatter(env.goal_pos[0], env.goal_pos[1], marker='X', color=get_color(env.goal_color), s=1000) # plots goal\n",
    "    plt.plot(traj['agent_pos'][:, 0], traj['agent_pos'][:, 1]) # plots trajs\n",
    "    plt.axis('off')\n",
    "    fig.savefig('test.pdf')\n",
    "print(env.goal)\n",
    "print(\"Average dist to goal: \", np.mean(dist_to_goals))\n",
    "print(\"Average std: \", np.std(dist_to_goals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b232b53c-9e67-4f14-9348-33b542b21d06",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "step = 0\n",
    "print(traj['true_goal'][step])\n",
    "state = traj['obs'][step].copy()\n",
    "plt.imshow(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c374940c-b2f6-4239-bd9e-7d7fdde30209",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mask = traj['masks'][step].copy()\n",
    "ax = sns.heatmap(test_mask[:,:,0])\n",
    "plt.show()\n",
    "threshold = 0.0012\n",
    "test_mask[test_mask>threshold] = 255\n",
    "test_mask[test_mask<=threshold] = 0\n",
    "ax = sns.heatmap(test_mask[:,:,0])\n",
    "plt.show()\n",
    "masked_state = state * test_mask\n",
    "#plt.imshow(traj['masked_states'][step])\n",
    "plt.imshow(masked_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61aa266-2dd0-4b0a-b2d1-24a5b30f8e80",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "finetune_trajs1 = gen_trajs(env, num_trajs=5, agent_pos=[0,1,2,3], obj_pos=[0,1,2,3], obj_colors=[2,3], scalar=5)\n",
    "finetune_trajs2 = gen_trajs(env, num_trajs=5, agent_pos=[0,1,2,3], obj_pos=[0,1,2,3], obj_colors=[2,3], scalar=5)\n",
    "finetune_trajs = finetune_trajs1 + finetune_trajs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4f77bc-d35b-4765-8760-a6610b43aa24",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "policy_copy = copy.deepcopy(policy)\n",
    "num_epochs = 1000\n",
    "batch_size = 50\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(list(policy_copy.parameters()))\n",
    "\n",
    "losses = []\n",
    "\n",
    "idxs = np.array(range(len(finetune_trajs)))\n",
    "\n",
    "num_batches = len(idxs) // batch_size\n",
    "# Train the model with regular SGD\n",
    "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "    np.random.shuffle(idxs)\n",
    "    running_loss = 0.0\n",
    "    for i in range(num_batches):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        t_idx = np.random.randint(len(finetune_trajs), size=(batch_size,)) # Indices of traj\n",
    "        t_idx_pertraj = np.random.randint(20, size=(batch_size,)) # Indices of timesteps in traj\n",
    "        t_states = np.concatenate([finetune_trajs[c_idx]['obs'][t_idx][None] for (c_idx, t_idx) in zip(t_idx, t_idx_pertraj)])\n",
    "        t_goals = np.concatenate([finetune_trajs[c_idx]['goal'][t_idx][None] for (c_idx, t_idx) in zip(t_idx, t_idx_pertraj)])\n",
    "        t_gt_masks = np.concatenate([finetune_trajs[c_idx]['gt_masks'][t_idx][None] for (c_idx, t_idx) in zip(t_idx, t_idx_pertraj)])\n",
    "        t_actions = np.concatenate([finetune_trajs[c_idx]['acts'][t_idx][None] for (c_idx, t_idx) in zip(t_idx, t_idx_pertraj)])\n",
    "   \n",
    "        t_states = torch.Tensor(t_states).float().to(device)\n",
    "        t_goals = torch.Tensor(t_goals).float().to(device)\n",
    "        #t_goals = torch.Tensor(lang_model.encode(t_goals.ravel())).float().to(device) # embeds goal through language model dim:384\n",
    "        t_gt_masks = torch.Tensor(t_gt_masks).float().to(device)\n",
    "        t_actions = torch.Tensor(t_actions).float().to(device)\n",
    "        \n",
    "        if mask:\n",
    "            a_preds, masked_state_preds, img_mask_preds = policy_copy(t_goals, t_states, t_gt_masks)\n",
    "            mask_loss = 5e-6*masked_state_preds.sum()\n",
    "        else:\n",
    "            a_preds = policy_copy(t_goals, t_states, t_gt_masks)[0]\n",
    "        \n",
    "        action_loss = torch.mean(torch.linalg.norm(a_preds - t_actions, dim=-1)) # supervised learning loss\n",
    "        #construal_loss = 1e-1*((state_mask_preds - t_construals)*(state_mask_preds - t_construals)).sum() # MSE supervised construal loss\n",
    "        if mask:\n",
    "            loss = action_loss + mask_loss\n",
    "        else:\n",
    "            loss = action_loss\n",
    "            mask_loss = 0\n",
    "        \n",
    "        loss.backward()\n",
    "        #print(policy_copy.conv[0].weight.grad)\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 0:\n",
    "            print('[%d, %5d] loss: %.8f' %\n",
    "                  (epoch + 1, i + 1, running_loss))\n",
    "            print('[%d, %5d] mask loss: %.8f' %\n",
    "                  (epoch + 1, i + 1, mask_loss))\n",
    "            print('[%d, %5d] action loss: %.8f' %\n",
    "                  (epoch + 1, i + 1, action_loss))\n",
    "            losses.append(running_loss)\n",
    "            running_loss = 0.0\n",
    "        losses.append(loss.item())\n",
    "\n",
    "print('Finished Training')\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c156e3c1-6af1-4617-bd8e-913b8374f442",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "policy_copy.eval()\n",
    "num_test_trajs = 20\n",
    "# sets sampling for angles and colors\n",
    "agent_pos=[2,3]\n",
    "obj_pos=[0,1]\n",
    "obj_colors=[0,1,2,3]\n",
    "scalar=5\n",
    "\n",
    "dist_to_goals = []\n",
    "\n",
    "for i in range(num_test_trajs):\n",
    "    env.reset(agent_pos, obj_pos, obj_colors, scalar)\n",
    "    goal = torch.Tensor(env.goal_color[None]).to(device)\n",
    "    #goal = torch.Tensor(lang_model.encode(env.goal)).to(device)\n",
    "    obs = plot_full_state(env.get_full_obs())\n",
    "    _, gt_mask = plot_img_mask(env.get_full_obs())\n",
    "    \n",
    "    traj = {'obs': [],'acts': [], 'true_goal': [], 'agent_pos': [], 'masked_states': [], 'masks': []}\n",
    "    for i in range(20):\n",
    "        state = torch.Tensor(obs[None]).to(device)\n",
    "        gt_mask = torch.Tensor(gt_mask[None]).to(device)\n",
    "        if mask:\n",
    "            action, masked_state, img_mask = policy_copy(goal,state,gt_mask)\n",
    "            action = action.cpu().detach().numpy()[0]\n",
    "            masked_state = masked_state.cpu().detach().numpy()[0].transpose((1,2,0))\n",
    "            img_mask = img_mask.cpu().detach().numpy()[0].transpose((1,2,0))\n",
    "            traj['masked_states'].append(masked_state)\n",
    "            traj['masks'].append(img_mask)\n",
    "        else:\n",
    "            action = policy_copy(goal,state,gt_mask)[0].cpu().detach().numpy()[0]\n",
    "        traj['obs'].append(obs.copy())\n",
    "        traj['acts'].append(action.copy())\n",
    "        traj['true_goal'].append(env.goal)\n",
    "        traj['agent_pos'].append(env.pos.tolist())\n",
    "        no, r, d, _ = env.step(action)\n",
    "        obs = plot_full_state(env.get_full_obs())\n",
    "        _, gt_mask = plot_img_mask(env.get_full_obs())\n",
    "    traj['obs'] = np.array(traj['obs'])\n",
    "    traj['acts'] = np.array(traj['acts'])\n",
    "    traj['true_goal'] = np.array(traj['true_goal'])\n",
    "    traj['agent_pos'] = np.array(traj['agent_pos'])\n",
    "    traj['masked_states'] = np.array(traj['masked_states'])\n",
    "    traj['masks'] = np.array(traj['masks'])\n",
    "    dist_to_goals.append(r.copy())\n",
    "    #print(\"Final dist to goal: \", r)\n",
    "    fig = plt.figure(figsize=(5, 5),facecolor=\"black\")\n",
    "    plt.xlim(-6, 6)\n",
    "    plt.ylim(-6, 6)\n",
    "    colors = sns.color_palette(\"hls\", 10)\n",
    "    plt.scatter(traj['agent_pos'][0][0], traj['agent_pos'][0][1], marker='v', color='white', s=200) # plots obj1\n",
    "    plt.scatter(env.obj1_pos[0], env.obj1_pos[1], marker='s', color=get_color(env.obj1_color), s=150) # plots obj1\n",
    "    plt.scatter(env.obj2_pos[0], env.obj2_pos[1], marker='s', color=get_color(env.obj2_color), s=150) # plots obj1\n",
    "    plt.scatter(env.goal_pos[0], env.goal_pos[1], marker='X', color=get_color(env.goal_color), s=1000) # plots goal\n",
    "    plt.plot(traj['agent_pos'][:, 0], traj['agent_pos'][:, 1]) # plots trajs\n",
    "    plt.axis('off')\n",
    "print(\"Average dist to goal: \", np.mean(dist_to_goals))\n",
    "print(\"Average std: \", np.std(dist_to_goals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687e01d6-a654-4f77-b1fb-d198e22fd7b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:aligning-construals] *",
   "language": "python",
   "name": "conda-env-aligning-construals-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
