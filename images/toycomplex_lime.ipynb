{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6cb5d2c-d3fb-4d20-8a51-74bf7e5f996e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "GCBC with point maze (with multi-goal + color state space)\n",
    "'''\n",
    "from __future__ import print_function, division, unicode_literals\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import io\n",
    "import json\n",
    "from io import open\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import distributions as pyd\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.ion()   # interactive mode - o\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "lang_model = SentenceTransformer('all-MiniLM-L6-v2', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bab2f33a-68b4-4950-803e-a7fcb2ca76fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom weight init for Conv2D and Linear layers\n",
    "def weight_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.orthogonal_(m.weight.data)\n",
    "        if hasattr(m.bias, \"data\"):\n",
    "            m.bias.data.fill_(0.0)\n",
    "                \n",
    "# helper mlp init function\n",
    "def mlp(input_dim, output_dim, hidden_dim, hidden_depth, output_mod=None):\n",
    "    if hidden_depth == 0:\n",
    "        mods = [nn.Linear(input_dim, output_dim)]\n",
    "    else:\n",
    "        mods = [nn.Linear(input_dim, hidden_dim), nn.ReLU(inplace=True)]\n",
    "        for i in range(hidden_depth - 1):\n",
    "            mods += [nn.Linear(hidden_dim, hidden_dim), nn.ReLU(inplace=True)]\n",
    "        mods.append(nn.Linear(hidden_dim, output_dim))\n",
    "    if output_mod is not None:\n",
    "        mods.append(output_mod)\n",
    "    trunk = nn.Sequential(*mods)\n",
    "    return trunk\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "# MLP policy\n",
    "class MLPPolicy(nn.Module):\n",
    "    def __init__(\n",
    "        self, obs_dim, action_dim, hidden_dim, hidden_depth, output_mod=None\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.trunk = mlp(input_dim, output_dim, hidden_dim, hidden_depth, output_mod)\n",
    "        self.outputs = dict()\n",
    "        self.apply(weight_init)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.trunk(x)\n",
    "\n",
    "# MLP policy\n",
    "class CNNPolicy(nn.Module):\n",
    "    def __init__(\n",
    "        self, goal_dim, action_dim, hidden_size, mask=False, output_mod=None):\n",
    "        super().__init__()\n",
    "        self.mask = mask\n",
    "        self.goal = mlp(goal_dim, hidden_size, hidden_dim=0, hidden_depth=0, output_mod=None) # => hidden_size\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(3,32,kernel_size=8,stride=4), nn.ReLU(inplace=True), nn.BatchNorm2d(32), #(b_size,3,36,36)=>(b_size,32,8,8)\n",
    "            nn.Conv2d(32,64,kernel_size=4,stride=2), nn.ReLU(inplace=True), nn.BatchNorm2d(64), #(b_size,32,8,8)=>(b_size,64,3,3)\n",
    "            nn.Conv2d(64,32,kernel_size=3,stride=1), nn.LeakyReLU(inplace=True), Flatten(), nn.BatchNorm1d(32), #(b_size,64,3,3)=>(b_size,32,1,1)=>(b_size,32*1*1)\n",
    "            nn.Linear(32*1*1, hidden_size) #(b_size,32*1*1)=>(b_size,hidden_size)\n",
    "        )\n",
    "        self.process = mlp(hidden_size*2, 1*36*36, hidden_dim=1000, hidden_depth=1, output_mod=nn.Sigmoid()) #(b_size,hidden_size*2)=>(b_size,32*1*1)\n",
    "        # UNet deconv mask --------------------------------------------------------------------------------------------------\n",
    "        #self.deconv = nn.Sequential(\n",
    "        #    nn.ConvTranspose2d(32, 64, kernel_size=3, stride=1), nn.LeakyReLU(inplace=True), nn.BatchNorm2d(64), #(b_size,32*1*1)=>(b_size,64,3,3)\n",
    "        #    nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2), nn.LeakyReLU(inplace=True), nn.BatchNorm2d(32), #(b_size,64,3,3)=>(b_size,32,8,8)\n",
    "        #    nn.ConvTranspose2d(32, 1, kernel_size=8, stride=4), nn.Sigmoid(), #(b_size,32,8,8)=>(b_size,3,36,36)\n",
    "        #)\n",
    "        self.cnntrunk = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=8, stride=4), nn.ReLU(inplace=True), nn.BatchNorm2d(32), #(b_size,3,36,36)=>(b_size,32,8,8)\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2), nn.ReLU(inplace=True), nn.BatchNorm2d(64), #(b_size,32,8,8)=>(b_size,64,3,3)\n",
    "            nn.Conv2d(64, 32, kernel_size=3, stride=1), nn.LeakyReLU(inplace=True), nn.BatchNorm2d(32), Flatten(), #(b_size,64,3,3)=>(b_size,32,1,1)=>(b_size,32*1*1)\n",
    "            nn.Linear(32*1*1, action_dim)#, nn.LeakyReLU(inplace=True), nn.BatchNorm1d(32), #(b_size,32*1*1)=>(b_size,hidden_size)\n",
    "            #nn.Linear(32, action_dim) #(b_size,hidden_size)=>(b_size,action_dim)\n",
    "        )\n",
    "        self.mlptrunk = mlp(hidden_size*2, action_dim, hidden_dim=100, hidden_depth=1) #(b_size,hidden_size*2)=>(b_size,action_dim)\n",
    "        self.apply(weight_init)\n",
    "\n",
    "    def forward(self, goal, state):\n",
    "        state = state/255.0 # process image + switch channels\n",
    "        state = state.permute(0,3,1,2)\n",
    "        state_embed = self.conv(state)\n",
    "        goal_embed = self.goal(goal) # process goal\n",
    "        goal_state = torch.cat((goal_embed,state_embed),dim=1) # process goal + state\n",
    "        \n",
    "        if self.mask:\n",
    "            img_mask = self.process(goal_state)\n",
    "            img_mask = img_mask.reshape(-1,1,36,36)\n",
    "            #img_mask = img_mask.reshape(-1,32,1,1)\n",
    "            #img_mask = self.deconv(img_mask) # deconv for mask\n",
    "            #--------------------- test with gt mask\n",
    "            #img_mask = gt_mask.reshape((-1, 36, 36, 1)) # reshape to 1 channel\n",
    "            #img_mask = np.repeat(img_mask, 3, axis=3) # duplicate across 3 channels\n",
    "            #img_mask = img_mask.permute(0,3,1,2) # process channel switch\n",
    "            #---------------------\n",
    "            masked_state = state * img_mask # apply mask to full state\n",
    "            pred = self.cnntrunk(masked_state)\n",
    "            return [pred, masked_state, img_mask]\n",
    "        else:\n",
    "            pred = self.mlptrunk(goal_state)\n",
    "            return [pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52cb612c-89dd-4f15-b5f7-4265c364721f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goal-conditioned Point Maze (with multi state + color)\n",
    "import gym\n",
    "import gym.wrappers\n",
    "\n",
    "class PointEnvGrid(gym.Env):\n",
    "    def __init__(self):\n",
    "        self.pos = np.array([99., 99.])\n",
    "        self.obj1_pos = np.array([99., 99.])\n",
    "        self.obj1_color = np.array([99., 99., 99., 99.])\n",
    "        self.obj1_shape = np.array([99., 99., 99., 99.])\n",
    "        self.obj2_pos = np.array([99., 99.])\n",
    "        self.obj2_color = np.array([99., 99., 99., 99.])\n",
    "        self.obj2_shape = np.array([99., 99., 99., 99.])\n",
    "        self.goal = np.array(['go to the red X'])\n",
    "        self.goal_pos = np.array([99., 99.])\n",
    "        self.goal_color = np.array([99., 99., 99., 99.])\n",
    "        self.goal_shape = np.array([99., 99., 99., 99.])\n",
    "        self.max_vel = 1.\n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            -np.inf * np.ones(14), np.inf * np.ones(14)\n",
    "        )\n",
    "        self.action_space = gym.spaces.Box(-np.ones(2), np.ones(2))\n",
    "        self.action_space.seed(0)\n",
    "        self.observation_space.seed(0)\n",
    "\n",
    "    # creates test env with defined goal locations + colors\n",
    "    def reset(self, agent_pos=[0,1,2,3], obj_pos=[0,1,2,3], obj_colors=[0,1,2,3], obj_shapes=[0,1,2,3], scalar=5):\n",
    "        # generates agent+objs without overlap\n",
    "        agent_loc = np.random.choice(agent_pos)\n",
    "        obj_pos = copy.deepcopy(obj_pos)\n",
    "        if agent_loc in obj_pos:\n",
    "            obj_pos.remove(agent_loc)\n",
    "        self.pos = self.gen_pos(agent_loc, scalar)\n",
    "        \n",
    "        obj1_loc, obj2_loc = random.sample(obj_pos, 2)\n",
    "        self.obj1_pos = self.gen_pos(obj1_loc, scalar)\n",
    "        self.obj1_color = self.gen_color(obj_colors)\n",
    "        self.obj1_shape = self.gen_shape(obj_shapes)\n",
    "        self.obj2_pos = self.gen_pos(obj2_loc, scalar)\n",
    "        self.obj2_color = self.gen_color(obj_colors)\n",
    "        self.obj2_shape = self.gen_shape(obj_shapes)\n",
    "\n",
    "        # choose goal from random in objects\n",
    "        goal_obj = random.randint(1, 2)\n",
    "        if goal_obj == 1:\n",
    "            self.goal_pos = self.obj1_pos\n",
    "            self.goal_color = self.obj1_color\n",
    "            self.goal_shape = self.obj1_shape\n",
    "        elif goal_obj == 2:\n",
    "            self.goal_pos = self.obj2_pos\n",
    "            self.goal_color = self.obj2_color\n",
    "            self.goal_shape = self.obj2_shape\n",
    "        self.goal = np.array(['go to the ' + get_color(self.goal_color) + ' ' + get_shape(self.goal_shape)])\n",
    "        return self.get_full_obs()\n",
    "\n",
    "    def get_obs(self):\n",
    "        return copy.deepcopy(np.concatenate([self.pos, self.obj1_pos, self.obj1_color, self.obj1_shape, self.obj2_pos, self.obj2_color, self.obj2_shape, self.goal_color, self.goal_shape]))\n",
    "    \n",
    "    def get_full_obs(self):\n",
    "        return copy.deepcopy(np.concatenate([self.pos, self.obj1_pos, self.obj1_color, self.obj1_shape, self.obj2_pos, self.obj2_color, self.obj2_shape, self.goal_pos, self.goal_color, self.goal_shape]))\n",
    "    \n",
    "    def step(self, action: np.ndarray):\n",
    "        self.pos += self.max_vel*action\n",
    "        reward = -np.linalg.norm((self.pos - self.goal_pos))\n",
    "        return self.get_full_obs(), reward, False, {}\n",
    "\n",
    "    # given a range of areas, randomly selects and generates position\n",
    "    def gen_pos(self, location, scalar):\n",
    "        if location == 0:\n",
    "            pos = np.array([-1.*scalar, 1.*scalar])\n",
    "        elif location == 1:\n",
    "            pos = np.array([1.*scalar, 1.*scalar])\n",
    "        elif location == 2:\n",
    "            pos = np.array([1.*scalar, -1.*scalar])\n",
    "        elif location == 3:\n",
    "            pos = np.array([-1.*scalar, -1.*scalar])\n",
    "        return pos\n",
    "\n",
    "    def gen_color(self, colors):\n",
    "        one_hot_color = np.zeros(shape=4) # defines total number of colors to choose from\n",
    "        rand_color = random.choice(colors) # samples color from range\n",
    "        one_hot_color[rand_color] = 1.\n",
    "        return one_hot_color\n",
    "\n",
    "    def gen_shape(self, shapes):\n",
    "        one_hot_shape = np.zeros(shape=4)\n",
    "        rand_shape = random.choice(shapes)\n",
    "        one_hot_shape[rand_shape] = 1.\n",
    "        return one_hot_shape\n",
    "\n",
    "class PointEnvComplex(gym.Env):\n",
    "    def __init__(self):\n",
    "        self.pos = np.array([99., 99.])\n",
    "        self.obj1_pos = np.array([99., 99.])\n",
    "        self.obj1_color = np.array([99., 99., 99.])\n",
    "        self.obj2_pos = np.array([99., 99.])\n",
    "        self.obj2_color = np.array([99., 99., 99.])\n",
    "        self.goal = np.array(['go to the red star'])\n",
    "        self.goal_pos = np.array([99., 99.])\n",
    "        self.goal_color = np.array([99., 99., 99.])\n",
    "        self.max_vel = 1.\n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            -np.inf * np.ones(14), np.inf * np.ones(14)\n",
    "        )\n",
    "        self.action_space = gym.spaces.Box(-np.ones(2), np.ones(2))\n",
    "        self.action_space.seed(0)\n",
    "        self.observation_space.seed(0)\n",
    "\n",
    "    # creates test env with defined goal locations + colors\n",
    "    def reset(self, obj_angles=360, obj_colors=[0,1,2], discretize=10):\n",
    "        self.pos = np.array([0., 0.])\n",
    "        self.obj1_pos, self.obj1_color = self.gen_obj(obj_angles, obj_colors, discretize)\n",
    "        self.obj2_pos, self.obj2_color = self.gen_obj(obj_angles, obj_colors, discretize)\n",
    "\n",
    "        # choose goal from random in objects\n",
    "        goal_obj = random.randint(1, 2)\n",
    "        if goal_obj == 1:\n",
    "            self.goal_pos = self.obj1_pos\n",
    "            self.goal_color = self.obj1_color\n",
    "        elif goal_obj == 2:\n",
    "            self.goal_pos = self.obj2_pos\n",
    "            self.goal_color = self.obj2_color\n",
    "        self.goal = np.array(['go to the ' + get_color(self.goal_color) + ' square'])\n",
    "        return self.get_obs()\n",
    "\n",
    "    def get_obs(self):\n",
    "        return copy.deepcopy(np.concatenate([self.pos, self.obj1_pos, self.obj1_color, self.obj2_pos, self.obj2_color, self.goal_color]))\n",
    "    \n",
    "    def get_full_obs(self):\n",
    "        return copy.deepcopy(np.concatenate([self.pos, self.obj1_pos, self.obj1_color, self.obj2_pos, self.obj2_color, self.goal_pos, self.goal_color]))\n",
    "    \n",
    "    def step(self, action: np.ndarray):\n",
    "        self.pos += self.max_vel*action\n",
    "        reward = -np.linalg.norm((self.pos - self.goal_pos))\n",
    "        return self.get_full_obs(), reward, False, {}\n",
    "\n",
    "    # function to generate object based on angles, colors, and discretization ranges\n",
    "    def gen_obj(self, obj_angles, obj_colors, discretize):\n",
    "        angle = np.random.uniform(0, obj_angles) # samples angle from range\n",
    "        angle = round(angle/discretize)*discretize # discretizes to defined range (default 10)\n",
    "        pos = np.array([5*np.cos(np.deg2rad(angle)), 5*np.sin(np.deg2rad(angle))]) # maps to unit circle\n",
    "        \n",
    "        color = np.zeros(shape = 3) # defines total number of colors to choose from\n",
    "        rand_color = random.sample(obj_colors,1) # samples color from range\n",
    "        color[rand_color] = 1.\n",
    "        return pos, color\n",
    "\n",
    "def get_color(color):\n",
    "    if color[0] == 1.:\n",
    "        return 'red'\n",
    "    elif color[1] == 1.:\n",
    "        return 'green'\n",
    "    elif color[2] == 1.:\n",
    "        return 'blue'\n",
    "    elif color[3] == 1.:\n",
    "        return 'yellow'\n",
    "\n",
    "def get_shape(shape):\n",
    "    if shape[0] == 1.:\n",
    "        return 'X'\n",
    "    elif shape[1] == 1.:\n",
    "        return 's'\n",
    "    elif shape[2] == 1.:\n",
    "        return '^'\n",
    "    elif shape[3] == 1.:\n",
    "        return 'd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a53268d-6609-4be9-8805-4ebbe3eb46d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_env(env):\n",
    "    fig = plt.figure(figsize=(5, 5),facecolor=\"black\")\n",
    "    plt.xlim(-6, 6)\n",
    "    plt.ylim(-6, 6)\n",
    "    plt.axis('off')\n",
    "    plt.scatter(env.pos[0],env.pos[1], marker='o', color='white', s=500) # plots agent\n",
    "    plt.scatter(env.obj1_pos[0], env.obj1_pos[1], marker=get_shape(env.obj1_shape), color=get_color(env.obj1_color), s=500) # plots obj1\n",
    "    plt.scatter(env.obj2_pos[0], env.obj2_pos[1], marker=get_shape(env.obj2_shape), color=get_color(env.obj2_color), s=500) # plots obj2\n",
    "    #plt.scatter(env.goal_pos[0], env.goal_pos[1], marker=get_shape(env.goal_shape), color=get_color(env.goal_color), s=1000) # plots goal\n",
    "    with io.BytesIO() as buff:\n",
    "        fig.savefig(buff, format='raw')\n",
    "        buff.seek(0)\n",
    "        data = np.frombuffer(buff.getvalue(), dtype=np.uint8)\n",
    "    w, h = fig.canvas.get_width_height()\n",
    "    img = data.reshape((int(h), int(w), -1))\n",
    "    img = img[:,:,:3]\n",
    "    plt.close()\n",
    "    return img\n",
    "\n",
    "def plot_full_state(state):\n",
    "    fig = plt.figure(figsize=(.5, .5),facecolor=\"black\")\n",
    "    plt.xlim(-6, 6)\n",
    "    plt.ylim(-6, 6)\n",
    "    plt.axis('off')\n",
    "    plt.scatter(state[0], state[1], marker='o', color='white', s=10) # plots agent\n",
    "    plt.scatter(state[2], state[3], marker=get_shape(state[8:12]), color=get_color(state[4:8]), s=10) # plots obj1\n",
    "    plt.scatter(state[12], state[13], marker=get_shape(state[18:22]), color=get_color(state[14:18]), s=10) # plots obj1\n",
    "    #plt.scatter(state[22], state[23], marker=get_shape(28:32), color=get_color(state[24:28]), s=15) # plots goal\n",
    "    with io.BytesIO() as buff:\n",
    "        fig.savefig(buff, format='raw')\n",
    "        buff.seek(0)\n",
    "        data = np.frombuffer(buff.getvalue(), dtype=np.uint8)\n",
    "    w, h = fig.canvas.get_width_height()\n",
    "    img = data.reshape((int(h), int(w), -1))\n",
    "    img = img[:,:,:3]\n",
    "    plt.close()\n",
    "    return img\n",
    "\n",
    "def plot_img_mask(state):\n",
    "    fig = plt.figure(figsize=(.5, .5),facecolor=\"black\")\n",
    "    plt.xlim(-6, 6)\n",
    "    plt.ylim(-6, 6)\n",
    "    plt.axis('off')\n",
    "    #plt.scatter(state[0], state[1], marker='o', color='white', s=10) # plots agent\n",
    "    #plt.scatter(state[2], state[3], marker=get_shape(state[8:12]), color=get_color(state[4:8]), s=10) # plots obj1\n",
    "    #plt.scatter(state[12], state[13], marker=get_shape(state[18:22]), color=get_color(state[14:18]), s=10) # plots obj1\n",
    "    plt.scatter(state[22], state[23], marker=get_shape(state[28:32]), color=get_color(state[24:28]), s=10) # plots goal\n",
    "    with io.BytesIO() as buff:\n",
    "        fig.savefig(buff, format='raw')\n",
    "        buff.seek(0)\n",
    "        data = np.frombuffer(buff.getvalue(), dtype=np.uint8)\n",
    "    w, h = fig.canvas.get_width_height()\n",
    "    img = data.reshape((int(h), int(w), -1))\n",
    "    img = img[:,:,:3]\n",
    "    img_mask = np.mean(img, axis=2)\n",
    "    img_mask[img_mask > 0] = 1\n",
    "    plt.close()\n",
    "    return img, img_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a346ba05-1d50-461f-8f77-93a6b2079bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generates random trajs within specified constraints\n",
    "def gen_trajs(env, num_trajs=1, agent_pos=[0,1,2,3], obj_pos=[0,1,2,3], obj_colors=[0,1,2,3], obj_shapes=[0,1,2,3], scalar=5):\n",
    "    trajs = []\n",
    "    for traj in range(num_trajs):\n",
    "        env.reset(agent_pos=agent_pos, obj_pos=obj_pos, obj_colors=obj_colors, obj_shapes=obj_shapes, scalar=scalar)\n",
    "        #plt.imshow(plot_env(env))\n",
    "        # rolls out a trajectory towards the goal\n",
    "        traj = {'obs': [],'acts': [],'goal': [], 'gt_masks': []}\n",
    "        delta_vector = env.goal_pos - env.pos\n",
    "        obs = plot_full_state(env.get_full_obs())\n",
    "        for i in range(20):\n",
    "            _, img_mask = plot_img_mask(env.get_full_obs())\n",
    "            act = delta_vector * 0.05 # Go in direction between start and end\n",
    "            traj['obs'].append(obs.copy())\n",
    "            traj['acts'].append(act.copy())\n",
    "            one_hot_goal = np.concatenate([env.goal_color, env.goal_shape])\n",
    "            traj['goal'].append(one_hot_goal)\n",
    "            traj['gt_masks'].append(img_mask)\n",
    "            no, r, d, _ = env.step(act)\n",
    "            obs = plot_full_state(no.copy())\n",
    "        traj['obs'] = np.array(traj['obs'])\n",
    "        traj['acts'] = np.array(traj['acts'])\n",
    "        traj['goal'] = np.array(traj['goal'])\n",
    "        traj['gt_masks'] = np.array(traj['gt_masks'])\n",
    "        #plt.plot(traj['obs'][:, 0], traj['obs'][:, 1]) # plots trajs + goals\n",
    "        trajs.append(traj)\n",
    "    return trajs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf371432-1fdb-4612-b7df-af5155e0c53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# colors = RGBY\n",
    "# shapes = Xs^d (star, square, triangle, diamond)\n",
    "env = PointEnvGrid()\n",
    "trajs = gen_trajs(env, num_trajs=50, agent_pos=[0], obj_pos=[2,3], obj_colors=[0,1], obj_shapes=[3], scalar=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f49b8ab-6efb-4001-848b-f8b92aa1e6fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2aeca8640>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#import seaborn as sns\n",
    "step = 0\n",
    "traj = 0\n",
    "state = trajs[traj]['obs'][step]\n",
    "gt_mask = trajs[traj]['gt_masks'][step]\n",
    "plt.imshow(gt_mask)\n",
    "gt_mask = gt_mask.reshape((36, 36, 1))\n",
    "gt_mask = np.repeat(gt_mask, 3, axis=2) # duplicate across 3 channels\n",
    "final_state = state * gt_mask # apply mask to full state\n",
    "plt.imshow(final_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d0c1a66-6ca4-487f-aec8-d174aea736e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2aed94130>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(trajs[traj]['obs'][step])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3a0e390-38e7-4d5c-b68a-2d3af1740f68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNPolicy(\n",
       "  (goal): Sequential(\n",
       "    (0): Linear(in_features=8, out_features=100, bias=True)\n",
       "  )\n",
       "  (conv): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(8, 8), stride=(4, 4))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (7): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    (8): Flatten()\n",
       "    (9): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): Linear(in_features=32, out_features=100, bias=True)\n",
       "  )\n",
       "  (process): Sequential(\n",
       "    (0): Linear(in_features=200, out_features=1000, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=1000, out_features=1296, bias=True)\n",
       "    (3): Sigmoid()\n",
       "  )\n",
       "  (cnntrunk): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(8, 8), stride=(4, 4))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (7): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): Flatten()\n",
       "    (10): Linear(in_features=32, out_features=2, bias=True)\n",
       "  )\n",
       "  (mlptrunk): Sequential(\n",
       "    (0): Linear(in_features=200, out_features=100, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=100, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tasks = len(trajs)\n",
    "\n",
    "goal_size = 8 #384\n",
    "env = PointEnvGrid()\n",
    "act_size = env.action_space.shape[0]\n",
    "hidden_size = 100\n",
    "mask = True\n",
    "\n",
    "policy = CNNPolicy(goal_size, act_size, hidden_size, mask=mask)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "policy.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2926811c-bf18-47d2-8ab1-f24d7af89b34",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] loss: 0.02504396\n",
      "[1,     1] mask loss: 0.00213094\n",
      "[1,     1] action loss: 0.02291302\n",
      "[2,     1] loss: 0.13288510\n",
      "[2,     1] mask loss: 0.00174848\n",
      "[2,     1] action loss: 0.13113661\n",
      "[3,     1] loss: 0.10985187\n",
      "[3,     1] mask loss: 0.00155229\n",
      "[3,     1] action loss: 0.10829958\n",
      "[4,     1] loss: 0.09553712\n",
      "[4,     1] mask loss: 0.00145206\n",
      "[4,     1] action loss: 0.09408505\n",
      "[5,     1] loss: 0.07909923\n",
      "[5,     1] mask loss: 0.00168307\n",
      "[5,     1] action loss: 0.07741616\n",
      "[6,     1] loss: 0.04377227\n",
      "[6,     1] mask loss: 0.00143492\n",
      "[6,     1] action loss: 0.04233735\n",
      "[7,     1] loss: 0.03871002\n",
      "[7,     1] mask loss: 0.00124690\n",
      "[7,     1] action loss: 0.03746312\n",
      "[8,     1] loss: 0.05039205\n",
      "[8,     1] mask loss: 0.00112631\n",
      "[8,     1] action loss: 0.04926574\n",
      "[9,     1] loss: 0.03177080\n",
      "[9,     1] mask loss: 0.00106165\n",
      "[9,     1] action loss: 0.03070915\n",
      "[10,     1] loss: 0.05132521\n",
      "[10,     1] mask loss: 0.00117636\n",
      "[10,     1] action loss: 0.05014885\n",
      "[11,     1] loss: 0.06716131\n",
      "[11,     1] mask loss: 0.00137434\n",
      "[11,     1] action loss: 0.06578697\n",
      "[12,     1] loss: 0.03006267\n",
      "[12,     1] mask loss: 0.00105694\n",
      "[12,     1] action loss: 0.02900573\n",
      "[13,     1] loss: 0.02759376\n",
      "[13,     1] mask loss: 0.00125202\n",
      "[13,     1] action loss: 0.02634174\n",
      "[14,     1] loss: 0.04294547\n",
      "[14,     1] mask loss: 0.00104687\n",
      "[14,     1] action loss: 0.04189860\n",
      "[15,     1] loss: 0.03222403\n",
      "[15,     1] mask loss: 0.00130346\n",
      "[15,     1] action loss: 0.03092057\n",
      "[16,     1] loss: 0.01856361\n",
      "[16,     1] mask loss: 0.00113005\n",
      "[16,     1] action loss: 0.01743356\n",
      "[17,     1] loss: 0.03029077\n",
      "[17,     1] mask loss: 0.00104586\n",
      "[17,     1] action loss: 0.02924491\n",
      "[18,     1] loss: 0.03508517\n",
      "[18,     1] mask loss: 0.00125783\n",
      "[18,     1] action loss: 0.03382734\n",
      "[19,     1] loss: 0.03092615\n",
      "[19,     1] mask loss: 0.00105900\n",
      "[19,     1] action loss: 0.02986715\n",
      "[20,     1] loss: 0.03219594\n",
      "[20,     1] mask loss: 0.00117953\n",
      "[20,     1] action loss: 0.03101641\n",
      "[21,     1] loss: 0.02082365\n",
      "[21,     1] mask loss: 0.00126928\n",
      "[21,     1] action loss: 0.01955437\n",
      "[22,     1] loss: 0.02230885\n",
      "[22,     1] mask loss: 0.00100601\n",
      "[22,     1] action loss: 0.02130283\n",
      "[23,     1] loss: 0.02087141\n",
      "[23,     1] mask loss: 0.00118340\n",
      "[23,     1] action loss: 0.01968802\n",
      "[24,     1] loss: 0.01746479\n",
      "[24,     1] mask loss: 0.00099316\n",
      "[24,     1] action loss: 0.01647163\n",
      "[25,     1] loss: 0.02392131\n",
      "[25,     1] mask loss: 0.00125299\n",
      "[25,     1] action loss: 0.02266832\n",
      "[26,     1] loss: 0.02126225\n",
      "[26,     1] mask loss: 0.00110544\n",
      "[26,     1] action loss: 0.02015681\n",
      "[27,     1] loss: 0.01508543\n",
      "[27,     1] mask loss: 0.00100181\n",
      "[27,     1] action loss: 0.01408362\n",
      "[28,     1] loss: 0.02006070\n",
      "[28,     1] mask loss: 0.00101516\n",
      "[28,     1] action loss: 0.01904554\n",
      "[29,     1] loss: 0.01301371\n",
      "[29,     1] mask loss: 0.00111177\n",
      "[29,     1] action loss: 0.01190194\n",
      "[30,     1] loss: 0.02022517\n",
      "[30,     1] mask loss: 0.00106167\n",
      "[30,     1] action loss: 0.01916350\n",
      "[31,     1] loss: 0.01362092\n",
      "[31,     1] mask loss: 0.00110196\n",
      "[31,     1] action loss: 0.01251896\n",
      "[32,     1] loss: 0.02003997\n",
      "[32,     1] mask loss: 0.00095371\n",
      "[32,     1] action loss: 0.01908626\n",
      "[33,     1] loss: 0.01341986\n",
      "[33,     1] mask loss: 0.00103086\n",
      "[33,     1] action loss: 0.01238900\n",
      "[34,     1] loss: 0.01354066\n",
      "[34,     1] mask loss: 0.00105321\n",
      "[34,     1] action loss: 0.01248745\n",
      "[35,     1] loss: 0.03249722\n",
      "[35,     1] mask loss: 0.00114520\n",
      "[35,     1] action loss: 0.03135202\n",
      "[36,     1] loss: 0.02412973\n",
      "[36,     1] mask loss: 0.00104656\n",
      "[36,     1] action loss: 0.02308318\n",
      "[37,     1] loss: 0.01121197\n",
      "[37,     1] mask loss: 0.00110651\n",
      "[37,     1] action loss: 0.01010546\n",
      "[38,     1] loss: 0.02510603\n",
      "[38,     1] mask loss: 0.00107046\n",
      "[38,     1] action loss: 0.02403556\n",
      "[39,     1] loss: 0.01595572\n",
      "[39,     1] mask loss: 0.00109390\n",
      "[39,     1] action loss: 0.01486182\n",
      "[40,     1] loss: 0.00954401\n",
      "[40,     1] mask loss: 0.00105460\n",
      "[40,     1] action loss: 0.00848942\n",
      "[41,     1] loss: 0.02589384\n",
      "[41,     1] mask loss: 0.00085570\n",
      "[41,     1] action loss: 0.02503814\n",
      "[42,     1] loss: 0.01420434\n",
      "[42,     1] mask loss: 0.00095428\n",
      "[42,     1] action loss: 0.01325006\n",
      "[43,     1] loss: 0.03417851\n",
      "[43,     1] mask loss: 0.00100650\n",
      "[43,     1] action loss: 0.03317200\n",
      "[44,     1] loss: 0.01086276\n",
      "[44,     1] mask loss: 0.00090152\n",
      "[44,     1] action loss: 0.00996125\n",
      "[45,     1] loss: 0.00970752\n",
      "[45,     1] mask loss: 0.00109352\n",
      "[45,     1] action loss: 0.00861400\n",
      "[46,     1] loss: 0.02010710\n",
      "[46,     1] mask loss: 0.00085903\n",
      "[46,     1] action loss: 0.01924806\n",
      "[47,     1] loss: 0.01817169\n",
      "[47,     1] mask loss: 0.00089395\n",
      "[47,     1] action loss: 0.01727775\n",
      "[48,     1] loss: 0.02009757\n",
      "[48,     1] mask loss: 0.00096630\n",
      "[48,     1] action loss: 0.01913127\n",
      "[49,     1] loss: 0.01033805\n",
      "[49,     1] mask loss: 0.00091801\n",
      "[49,     1] action loss: 0.00942003\n",
      "[50,     1] loss: 0.01277026\n",
      "[50,     1] mask loss: 0.00090698\n",
      "[50,     1] action loss: 0.01186328\n",
      "[51,     1] loss: 0.01027791\n",
      "[51,     1] mask loss: 0.00084404\n",
      "[51,     1] action loss: 0.00943388\n",
      "[52,     1] loss: 0.01127613\n",
      "[52,     1] mask loss: 0.00091802\n",
      "[52,     1] action loss: 0.01035811\n",
      "[53,     1] loss: 0.00956987\n",
      "[53,     1] mask loss: 0.00082062\n",
      "[53,     1] action loss: 0.00874925\n",
      "[54,     1] loss: 0.00890184\n",
      "[54,     1] mask loss: 0.00082406\n",
      "[54,     1] action loss: 0.00807777\n",
      "[55,     1] loss: 0.01792495\n",
      "[55,     1] mask loss: 0.00078671\n",
      "[55,     1] action loss: 0.01713824\n",
      "[56,     1] loss: 0.00984847\n",
      "[56,     1] mask loss: 0.00091830\n",
      "[56,     1] action loss: 0.00893018\n",
      "[57,     1] loss: 0.00954755\n",
      "[57,     1] mask loss: 0.00084194\n",
      "[57,     1] action loss: 0.00870561\n",
      "[58,     1] loss: 0.01716420\n",
      "[58,     1] mask loss: 0.00086298\n",
      "[58,     1] action loss: 0.01630122\n",
      "[59,     1] loss: 0.00738215\n",
      "[59,     1] mask loss: 0.00081729\n",
      "[59,     1] action loss: 0.00656486\n",
      "[60,     1] loss: 0.00859142\n",
      "[60,     1] mask loss: 0.00089903\n",
      "[60,     1] action loss: 0.00769239\n",
      "[61,     1] loss: 0.00951725\n",
      "[61,     1] mask loss: 0.00076339\n",
      "[61,     1] action loss: 0.00875386\n",
      "[62,     1] loss: 0.00973320\n",
      "[62,     1] mask loss: 0.00084053\n",
      "[62,     1] action loss: 0.00889267\n",
      "[63,     1] loss: 0.01866560\n",
      "[63,     1] mask loss: 0.00090943\n",
      "[63,     1] action loss: 0.01775618\n",
      "[64,     1] loss: 0.01713663\n",
      "[64,     1] mask loss: 0.00086836\n",
      "[64,     1] action loss: 0.01626826\n",
      "[65,     1] loss: 0.00933130\n",
      "[65,     1] mask loss: 0.00095037\n",
      "[65,     1] action loss: 0.00838092\n",
      "[66,     1] loss: 0.01849503\n",
      "[66,     1] mask loss: 0.00093945\n",
      "[66,     1] action loss: 0.01755558\n",
      "[67,     1] loss: 0.01789295\n",
      "[67,     1] mask loss: 0.00068671\n",
      "[67,     1] action loss: 0.01720624\n",
      "[68,     1] loss: 0.01087175\n",
      "[68,     1] mask loss: 0.00068920\n",
      "[68,     1] action loss: 0.01018255\n",
      "[69,     1] loss: 0.01102916\n",
      "[69,     1] mask loss: 0.00091524\n",
      "[69,     1] action loss: 0.01011393\n",
      "[70,     1] loss: 0.00980043\n",
      "[70,     1] mask loss: 0.00087158\n",
      "[70,     1] action loss: 0.00892885\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m     loss \u001b[38;5;241m=\u001b[39m action_loss\n\u001b[1;32m     45\u001b[0m     mask_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 47\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m#print(policy.conv[0].weight.grad)\u001b[39;00m\n\u001b[1;32m     49\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/miniforge3/envs/aligning-construals/lib/python3.9/site-packages/torch/_tensor.py:307\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    300\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    301\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    305\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    306\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 307\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/aligning-construals/lib/python3.9/site-packages/torch/autograd/__init__.py:154\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m--> 154\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 1500\n",
    "batch_size = 50\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(list(policy.parameters()))\n",
    "\n",
    "losses = []\n",
    "\n",
    "idxs = np.array(range(len(trajs)))\n",
    "\n",
    "num_batches = len(idxs) // batch_size\n",
    "# Train the model with regular SGD\n",
    "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "    np.random.shuffle(idxs)\n",
    "    running_loss = 0.0\n",
    "    for i in range(num_batches):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        t_idx = np.random.randint(len(trajs), size=(batch_size,)) # Indices of traj\n",
    "        t_idx_pertraj = np.random.randint(20, size=(batch_size,)) # Indices of timesteps in traj\n",
    "        t_states = np.concatenate([trajs[c_idx]['obs'][t_idx][None] for (c_idx, t_idx) in zip(t_idx, t_idx_pertraj)])\n",
    "        t_goals = np.concatenate([trajs[c_idx]['goal'][t_idx][None] for (c_idx, t_idx) in zip(t_idx, t_idx_pertraj)])\n",
    "        #t_gt_masks = np.concatenate([trajs[c_idx]['gt_masks'][t_idx][None] for (c_idx, t_idx) in zip(t_idx, t_idx_pertraj)])\n",
    "        t_actions = np.concatenate([trajs[c_idx]['acts'][t_idx][None] for (c_idx, t_idx) in zip(t_idx, t_idx_pertraj)])\n",
    "   \n",
    "        t_states = torch.Tensor(t_states).float().to(device)\n",
    "        t_goals = torch.Tensor(t_goals).float().to(device)\n",
    "        #t_goals = torch.Tensor(lang_model.encode(t_goals.ravel())).float().to(device) # embeds goal through language model dim:384\n",
    "        #t_gt_masks = torch.Tensor(t_gt_masks).float().to(device)\n",
    "        t_actions = torch.Tensor(t_actions).float().to(device)\n",
    "        \n",
    "        if mask:\n",
    "            a_preds, masked_state_preds, img_mask_preds = policy(t_goals, t_states)\n",
    "            mask_loss = 5e-6*masked_state_preds.sum()\n",
    "        else:\n",
    "            a_preds = policy(t_goals, t_states)[0]\n",
    "        \n",
    "        action_loss = torch.mean(torch.linalg.norm(a_preds - t_actions, dim=-1)) # supervised learning loss\n",
    "        #construal_loss = 1e-1*((state_mask_preds - t_construals)*(state_mask_preds - t_construals)).sum() # MSE supervised construal loss\n",
    "        if mask:\n",
    "            loss = action_loss + mask_loss\n",
    "        else:\n",
    "            loss = action_loss\n",
    "            mask_loss = 0\n",
    "        \n",
    "        loss.backward()\n",
    "        #print(policy.conv[0].weight.grad)\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 0:\n",
    "            print('[%d, %5d] loss: %.8f' %\n",
    "                  (epoch + 1, i + 1, running_loss))\n",
    "            print('[%d, %5d] mask loss: %.8f' %\n",
    "                  (epoch + 1, i + 1, mask_loss))\n",
    "            print('[%d, %5d] action loss: %.8f' %\n",
    "                  (epoch + 1, i + 1, action_loss))\n",
    "            losses.append(running_loss)\n",
    "            running_loss = 0.0\n",
    "        losses.append(loss.item())\n",
    "\n",
    "print('Finished Training')\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a7599da5-05c3-4b59-8538-a1a0cd72d371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['go to the red d']\n",
      "Average dist to goal:  -0.10327747800431017\n",
      "Average std:  0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mask = True\n",
    "policy.eval()\n",
    "num_test_trajs = 1\n",
    "# sets sampling for angles and colors\n",
    "agent_pos=[0]\n",
    "obj_pos=[2,3]\n",
    "obj_colors=[0,1]\n",
    "obj_shapes=[3]\n",
    "scalar=5\n",
    "\n",
    "dist_to_goals = []\n",
    "\n",
    "for i in range(num_test_trajs):\n",
    "    env.reset(agent_pos, obj_pos, obj_colors, obj_shapes, scalar)\n",
    "    one_hot_goal = np.concatenate([env.goal_color, env.goal_shape])\n",
    "    goal = torch.Tensor(one_hot_goal[None]).to(device)\n",
    "    #goal = torch.Tensor(lang_model.encode(env.goal)).to(device)\n",
    "    obs = plot_full_state(env.get_full_obs())\n",
    "    _, gt_mask = plot_img_mask(env.get_full_obs())\n",
    "    \n",
    "    traj = {'obs': [],'acts': [], 'true_goal': [], 'agent_pos': [], 'masked_states': [], 'masks': [], 'gt_masks': []}\n",
    "    for i in range(20):\n",
    "        state = torch.Tensor(obs[None]).to(device)\n",
    "        gt_mask = torch.Tensor(gt_mask[None]).to(device)\n",
    "        if mask:\n",
    "            action, masked_state, img_mask = policy(goal,state)\n",
    "            action = action.cpu().detach().numpy()[0]\n",
    "            masked_state = masked_state.cpu().detach().numpy()[0].transpose((1,2,0))\n",
    "            img_mask = img_mask.cpu().detach().numpy()[0].transpose((1,2,0))\n",
    "            traj['masked_states'].append(masked_state)\n",
    "            traj['masks'].append(img_mask)\n",
    "        else:\n",
    "            action = policy(goal,state)[0].cpu().detach().numpy()[0]\n",
    "        traj['obs'].append(obs.copy())\n",
    "        traj['acts'].append(action.copy())\n",
    "        traj['true_goal'].append(env.goal)\n",
    "        traj['agent_pos'].append(env.pos.tolist())\n",
    "        no, r, d, _ = env.step(action)\n",
    "        obs = plot_full_state(env.get_full_obs())\n",
    "        _, gt_mask = plot_img_mask(env.get_full_obs())\n",
    "    traj['obs'] = np.array(traj['obs'])\n",
    "    traj['acts'] = np.array(traj['acts'])\n",
    "    traj['true_goal'] = np.array(traj['true_goal'])\n",
    "    traj['agent_pos'] = np.array(traj['agent_pos'])\n",
    "    traj['masked_states'] = np.array(traj['masked_states'])\n",
    "    traj['masks'] = np.array(traj['masks'])\n",
    "    dist_to_goals.append(r.copy())\n",
    "    #print(\"Final dist to goal: \", r)\n",
    "    fig = plt.figure(figsize=(5, 5),facecolor=\"black\")\n",
    "    plt.xlim(-6, 6)\n",
    "    plt.ylim(-6, 6)\n",
    "    colors = sns.color_palette(\"hls\", 10)\n",
    "    plt.scatter(traj['agent_pos'][0][0], traj['agent_pos'][0][1], marker='o', color='white', s=200) # plots obj1\n",
    "    plt.scatter(env.obj1_pos[0], env.obj1_pos[1], marker=get_shape(env.obj1_shape), color=get_color(env.obj1_color), s=200) # plots obj1\n",
    "    plt.scatter(env.obj2_pos[0], env.obj2_pos[1], marker=get_shape(env.obj2_shape), color=get_color(env.obj2_color), s=200) # plots obj1\n",
    "    #plt.scatter(env.goal_pos[0], env.goal_pos[1], marker='X', color=get_color(env.goal_color), s=1000) # plots goal\n",
    "    plt.plot(traj['agent_pos'][:, 0], traj['agent_pos'][:, 1]) # plots trajs\n",
    "    plt.axis('off')\n",
    "print(env.goal)\n",
    "print(\"Average dist to goal: \", np.mean(dist_to_goals))\n",
    "print(\"Average std: \", np.std(dist_to_goals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "72ca9822-9b86-4ba6-9ae6-dad15f14a911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(traj['obs'][0])\n",
    "lime_obs = traj['obs'][0]#.transpose(2,0,1)\n",
    "lime_goal = one_hot_goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7fef56bd-9dcd-4f91-90e9-21320b0bb9ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0., 0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "print(goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6379d393-4acd-45f0-857a-a357deaf6bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_predict(goals, obs):\n",
    "    policy.eval()\n",
    "    policy.to(device)\n",
    "    \n",
    "    obs = torch.Tensor(obs).to(device)\n",
    "    batches = obs.shape[0]\n",
    "    goals = torch.Tensor([goals]).to(device)\n",
    "    goals = goals.repeat(batches, 1)\n",
    "    #obs = torch.stack((obs, goals), dim=0)\n",
    "    \n",
    "    logits, _, _ = policy(goals, obs)\n",
    "    #probs = F.softmax(logits, dim=1)\n",
    "    return logits.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f532d625-390b-4568-a7c7-95772d062dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.54419285 -0.4857239 ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import partial\n",
    "g = partial(batch_predict, [0., 1., 0., 0., 0., 0., 0., 1.])\n",
    "test_pred = g([lime_obs])\n",
    "print(test_pred)\n",
    "test_pred.squeeze().argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0f8bf44f-6f12-41c2-952c-31a9536cc69a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a51b8cc33714d13b852e742d12c2c3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from lime import lime_image\n",
    "explainer = lime_image.LimeImageExplainer()\n",
    "explanation = explainer.explain_instance(np.array(lime_obs), \n",
    "                                         g, # prediction function\n",
    "                                         top_labels=5, \n",
    "                                         hide_color=0, \n",
    "                                         num_samples=1000) # number of images that will be sent to classification function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "98ecb8ef-8544-44e0-a0c4-a38e0a637acc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2e3480640>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from skimage.segmentation import mark_boundaries\n",
    "temp, mask1 = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=5, hide_rest=False)\n",
    "img_boundry1 = mark_boundaries(temp/255.0, mask1)\n",
    "plt.imshow(img_boundry1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f08e4b35-550b-447a-ad75-2b6888d492b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2e3398970>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp, mask1 = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=False, num_features=10, hide_rest=False)\n",
    "img_boundry2 = mark_boundaries(temp/255.0, mask1)\n",
    "plt.imshow(img_boundry2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f891dd0-a52b-4946-82a9-5899ce12f714",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:aligning-construals] *",
   "language": "python",
   "name": "conda-env-aligning-construals-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
